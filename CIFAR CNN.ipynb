{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1fab35-4fec-4ce5-a562-00e297fcc7f9",
   "metadata": {},
   "source": [
    "# RealNet CNN CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "915b6275-c75e-43f7-9c1b-bef0b6f27fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch device: cuda\n",
      "======================================================================\n",
      "BLOCK 1: RealNet Training with Frozen CNN (CIFAR-10)\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  • Dataset: CIFAR-10 (32×32 RGB)\n",
      "  • CNN Backbone: ResNet18 (ImageNet pre-trained, FROZEN)\n",
      "  • Feature dimension: 512\n",
      "  • Batch size: 128\n",
      "  • Patience: 10\n",
      "  • Seeds: [42, 123, 456]\n",
      "  • Architecture: CNN(frozen) → 512 → 128 → 10\n",
      "======================================================================\n",
      "\n",
      "Creating stratified samples...\n",
      "  Sampling took 0.00s\n",
      "  Train samples: 15000 (stratified, 1500 per class)\n",
      "  Test samples:  3000 (stratified, 300 per class)\n",
      "\n",
      "======================================================================\n",
      "SEED 42\n",
      "======================================================================\n",
      "\n",
      "  Training RealNet-CNN (seed=42)...\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/dustoff06/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:01<00:00, 30.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Real-CNN] Epoch  1 | loss=1.8288 | test_acc=0.4087 | time=1.2s\n",
      "  [Real-CNN] Epoch  2 | loss=1.5903 | test_acc=0.4397 | time=1.9s\n",
      "  [Real-CNN] Epoch  3 | loss=1.5181 | test_acc=0.4413 | time=2.5s\n",
      "  [Real-CNN] Epoch  4 | loss=1.4819 | test_acc=0.4503 | time=3.2s\n",
      "  [Real-CNN] Epoch  5 | loss=1.4372 | test_acc=0.4463 | time=3.8s\n",
      "  [Real-CNN] Epoch  6 | loss=1.4145 | test_acc=0.4527 | time=4.4s\n",
      "  [Real-CNN] Epoch  7 | loss=1.3820 | test_acc=0.4633 | time=5.0s\n",
      "  [Real-CNN] Epoch  8 | loss=1.3512 | test_acc=0.4660 | time=5.6s\n",
      "  [Real-CNN] Epoch  9 | loss=1.3328 | test_acc=0.4543 | time=6.2s\n",
      "  [Real-CNN] Epoch 10 | loss=1.2916 | test_acc=0.4593 | time=6.8s\n",
      "  [Real-CNN] Epoch 11 | loss=1.2570 | test_acc=0.4657 | time=7.4s\n",
      "  [Real-CNN] Epoch 12 | loss=1.2416 | test_acc=0.4533 | time=8.0s\n",
      "  [Real-CNN] Epoch 13 | loss=1.2096 | test_acc=0.4527 | time=8.6s\n",
      "  [Real-CNN] Epoch 14 | loss=1.1876 | test_acc=0.4543 | time=9.2s\n",
      "  [Real-CNN] Epoch 15 | loss=1.1723 | test_acc=0.4560 | time=9.8s\n",
      "  [Real-CNN] Epoch 16 | loss=1.1461 | test_acc=0.4533 | time=10.4s\n",
      "  [Real-CNN] Epoch 17 | loss=1.1226 | test_acc=0.4587 | time=11.0s\n",
      "  [Real-CNN] Epoch 18 | loss=1.1014 | test_acc=0.4683 | time=11.6s\n",
      "  [Real-CNN] Epoch 19 | loss=1.0790 | test_acc=0.4557 | time=12.2s\n",
      "  [Real-CNN] Epoch 20 | loss=1.0759 | test_acc=0.4477 | time=12.8s\n",
      "  [Real-CNN] Epoch 21 | loss=1.0616 | test_acc=0.4480 | time=13.4s\n",
      "  [Real-CNN] Epoch 22 | loss=1.0323 | test_acc=0.4533 | time=14.0s\n",
      "  [Real-CNN] Epoch 23 | loss=1.0283 | test_acc=0.4520 | time=14.6s\n",
      "  [Real-CNN] Epoch 24 | loss=1.0118 | test_acc=0.4577 | time=15.2s\n",
      "  [Real-CNN] Epoch 25 | loss=0.9934 | test_acc=0.4500 | time=15.8s\n",
      "  [Real-CNN] Epoch 26 | loss=0.9666 | test_acc=0.4467 | time=16.5s\n",
      "  [Real-CNN] Epoch 27 | loss=0.9710 | test_acc=0.4480 | time=17.1s\n",
      "  [Real-CNN] Epoch 28 | loss=0.9354 | test_acc=0.4583 | time=17.7s\n",
      "  [Real-CNN] Early stop at epoch 28 (no improvement for 10 epochs)\n",
      "\n",
      "  → Saved frozen CNN state from seed 42\n",
      "\n",
      "======================================================================\n",
      "SEED 123\n",
      "======================================================================\n",
      "\n",
      "  Training RealNet-CNN (seed=123)...\n",
      "  [Real-CNN] Epoch  1 | loss=1.8229 | test_acc=0.4303 | time=0.6s\n",
      "  [Real-CNN] Epoch  2 | loss=1.5834 | test_acc=0.4343 | time=1.3s\n",
      "  [Real-CNN] Epoch  3 | loss=1.5202 | test_acc=0.4433 | time=1.9s\n",
      "  [Real-CNN] Epoch  4 | loss=1.4735 | test_acc=0.4423 | time=2.5s\n",
      "  [Real-CNN] Epoch  5 | loss=1.4398 | test_acc=0.4540 | time=3.1s\n",
      "  [Real-CNN] Epoch  6 | loss=1.4179 | test_acc=0.4727 | time=3.8s\n",
      "  [Real-CNN] Epoch  7 | loss=1.3754 | test_acc=0.4723 | time=4.4s\n",
      "  [Real-CNN] Epoch  8 | loss=1.3367 | test_acc=0.4570 | time=5.0s\n",
      "  [Real-CNN] Epoch  9 | loss=1.3143 | test_acc=0.4700 | time=5.6s\n",
      "  [Real-CNN] Epoch 10 | loss=1.2888 | test_acc=0.4810 | time=6.2s\n",
      "  [Real-CNN] Epoch 11 | loss=1.2690 | test_acc=0.4730 | time=6.8s\n",
      "  [Real-CNN] Epoch 12 | loss=1.2352 | test_acc=0.4670 | time=7.4s\n",
      "  [Real-CNN] Epoch 13 | loss=1.2133 | test_acc=0.4683 | time=8.0s\n",
      "  [Real-CNN] Epoch 14 | loss=1.1905 | test_acc=0.4613 | time=8.6s\n",
      "  [Real-CNN] Epoch 15 | loss=1.1756 | test_acc=0.4657 | time=9.2s\n",
      "  [Real-CNN] Epoch 16 | loss=1.1495 | test_acc=0.4643 | time=9.8s\n",
      "  [Real-CNN] Epoch 17 | loss=1.1338 | test_acc=0.4630 | time=10.4s\n",
      "  [Real-CNN] Epoch 18 | loss=1.1100 | test_acc=0.4690 | time=11.1s\n",
      "  [Real-CNN] Epoch 19 | loss=1.0916 | test_acc=0.4657 | time=11.7s\n",
      "  [Real-CNN] Epoch 20 | loss=1.0604 | test_acc=0.4560 | time=12.3s\n",
      "  [Real-CNN] Early stop at epoch 20 (no improvement for 10 epochs)\n",
      "\n",
      "======================================================================\n",
      "SEED 456\n",
      "======================================================================\n",
      "\n",
      "  Training RealNet-CNN (seed=456)...\n",
      "  [Real-CNN] Epoch  1 | loss=1.8198 | test_acc=0.4043 | time=0.6s\n",
      "  [Real-CNN] Epoch  2 | loss=1.5911 | test_acc=0.4240 | time=1.2s\n",
      "  [Real-CNN] Epoch  3 | loss=1.5194 | test_acc=0.4350 | time=1.8s\n",
      "  [Real-CNN] Epoch  4 | loss=1.4825 | test_acc=0.4443 | time=2.5s\n",
      "  [Real-CNN] Epoch  5 | loss=1.4392 | test_acc=0.4533 | time=3.1s\n",
      "  [Real-CNN] Epoch  6 | loss=1.4193 | test_acc=0.4510 | time=3.7s\n",
      "  [Real-CNN] Epoch  7 | loss=1.3832 | test_acc=0.4477 | time=4.3s\n",
      "  [Real-CNN] Epoch  8 | loss=1.3520 | test_acc=0.4640 | time=4.9s\n",
      "  [Real-CNN] Epoch  9 | loss=1.3277 | test_acc=0.4647 | time=5.5s\n",
      "  [Real-CNN] Epoch 10 | loss=1.3028 | test_acc=0.4617 | time=6.1s\n",
      "  [Real-CNN] Epoch 11 | loss=1.2648 | test_acc=0.4437 | time=6.7s\n",
      "  [Real-CNN] Epoch 12 | loss=1.2534 | test_acc=0.4607 | time=7.3s\n",
      "  [Real-CNN] Epoch 13 | loss=1.2266 | test_acc=0.4637 | time=8.0s\n",
      "  [Real-CNN] Epoch 14 | loss=1.1945 | test_acc=0.4630 | time=8.6s\n",
      "  [Real-CNN] Epoch 15 | loss=1.1799 | test_acc=0.4620 | time=9.2s\n",
      "  [Real-CNN] Epoch 16 | loss=1.1412 | test_acc=0.4633 | time=10.0s\n",
      "  [Real-CNN] Epoch 17 | loss=1.1406 | test_acc=0.4613 | time=11.3s\n",
      "  [Real-CNN] Epoch 18 | loss=1.1079 | test_acc=0.4610 | time=11.9s\n",
      "  [Real-CNN] Epoch 19 | loss=1.0927 | test_acc=0.4577 | time=12.6s\n",
      "  [Real-CNN] Early stop at epoch 19 (no improvement for 10 epochs)\n",
      "\n",
      "======================================================================\n",
      "REALNET-CNN SUMMARY (CIFAR-10)\n",
      "======================================================================\n",
      "\n",
      "Accuracy:          0.4713 ± 0.0070\n",
      "Time:              14.2s ± 2.5s\n",
      "Epochs:            22.3 ± 4.0\n",
      "Trainable params:  66,954\n",
      "Total params:      11,243,466\n",
      "Frozen params:     11,176,512\n",
      "\n",
      "Per-seed results:\n",
      "  Seed 42: acc=0.4683, time=17.7s, epochs=28\n",
      "  Seed 123: acc=0.4810, time=12.3s, epochs=20\n",
      "  Seed 456: acc=0.4647, time=12.6s, epochs=19\n",
      "\n",
      "✓ Saved results to: realnet_cnn_cifar10_results.pt\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Block 1: RealNet Training with Frozen CNN (CIFAR-10)\n",
    "====================================================\n",
    "Trains the baseline Real MLP head on top of frozen ResNet18 features.\n",
    "Uses 3 seeds on CIFAR-10 with stratified sampling.\n",
    "Saves the frozen CNN state for reuse in subsequent blocks.\n",
    "\n",
    "Outputs:\n",
    "- realnet_cnn_cifar10_results.pt: Contains results dict and frozen CNN state\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using PyTorch device: {device}\")\n",
    "\n",
    "# ============================================\n",
    "# Comprehensive seed setting for reproducibility\n",
    "# ============================================\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    \"\"\"Set seeds for all RNG sources for reproducibility\"\"\"\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    # Python\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # PyTorch deterministic mode\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # CuPy (if available)\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        cp.random.seed(seed)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # PennyLane (if available)\n",
    "    try:\n",
    "        import pennylane as qml\n",
    "        qml.numpy.random.seed(seed)\n",
    "    except (ImportError, AttributeError):\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Frozen CNN Feature Extractor (ResNet18)\n",
    "# ============================================\n",
    "\n",
    "class FrozenCNNExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Frozen ResNet18 feature extractor.\n",
    "    Outputs 512-dimensional features from penultimate layer.\n",
    "    Pre-trained on ImageNet.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load pre-trained ResNet18\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        resnet = resnet18(weights=weights)\n",
    "        \n",
    "        # Remove the final FC layer (we only want features)\n",
    "        # ResNet18 structure: conv layers -> avgpool -> fc\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "        # Freeze all parameters\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.eval()  # Set to eval mode permanently\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():  # No gradients needed\n",
    "            features = self.features(x)\n",
    "            # Output shape: (batch, 512, 1, 1)\n",
    "            features = features.view(features.size(0), -1)  # Flatten to (batch, 512)\n",
    "        return features\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Real-valued Head\n",
    "# ============================================\n",
    "\n",
    "class RealHead(nn.Module):\n",
    "    \"\"\"Standard MLP: 512 → 128 → 10\"\"\"\n",
    "    def __init__(self, input_dim=512, hidden_dim=128, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RealNetCNN(nn.Module):\n",
    "    \"\"\"Complete Real network: Frozen CNN + RealHead\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_extractor = FrozenCNNExtractor()\n",
    "        self.head = RealHead(512, 128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn_extractor(x)\n",
    "        return self.head(features)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Training and Evaluation\n",
    "# ============================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device, show_progress=False):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total_samples += x.size(0)\n",
    "\n",
    "        if show_progress and batch_idx % 50 == 0:\n",
    "            print(f\"    Batch {batch_idx}/{len(loader)}, samples: {total_samples}\", end=\"\\r\")\n",
    "\n",
    "    if show_progress:\n",
    "        print()\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "def train_with_early_stopping(model, train_loader, test_loader, optimizer,\n",
    "                              device, max_epochs=40, patience=10, name=\"Model\"):\n",
    "    if isinstance(device, str):\n",
    "        device = torch.device(device)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    start = time.time()\n",
    "    last_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        loss = train_one_epoch(model, train_loader, optimizer, device, show_progress=False)\n",
    "        acc = evaluate(model, test_loader, device)\n",
    "        last_acc = acc\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"  [{name}] Epoch {epoch:2d} | loss={loss:.4f} \"\n",
    "              f\"| test_acc={acc:.4f} | time={elapsed:.1f}s\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"  [{name}] Early stop at epoch {epoch} \"\n",
    "                  f\"(no improvement for {patience} epochs)\")\n",
    "            break\n",
    "\n",
    "    total_time = time.time() - start\n",
    "    return {\n",
    "        \"best_acc\": best_acc,\n",
    "        \"final_acc\": last_acc,\n",
    "        \"time\": total_time,\n",
    "        \"epochs\": epoch,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Data utilities\n",
    "# ============================================\n",
    "\n",
    "def stratified_sample_from_targets(dataset, n_samples_per_class, seed=42):\n",
    "    \"\"\"\n",
    "    Create a stratified sample with n_samples_per_class from each class.\n",
    "    Uses dataset.targets directly - NO image loading during sampling.\n",
    "    \"\"\"\n",
    "    if hasattr(dataset, 'targets'):\n",
    "        targets = np.array(dataset.targets)\n",
    "    else:\n",
    "        targets = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "    \n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    sampled_indices = []\n",
    "    for c in range(10):\n",
    "        idx_c = np.where(targets == c)[0]\n",
    "        k = min(n_samples_per_class, len(idx_c))\n",
    "        selected = rng.choice(idx_c, size=k, replace=False).tolist()\n",
    "        sampled_indices.extend(selected)\n",
    "    \n",
    "    rng.shuffle(sampled_indices)\n",
    "    return sampled_indices\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Main\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BLOCK 1: RealNet Training with Frozen CNN (CIFAR-10)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nConfiguration:\")\n",
    "    print(\"  • Dataset: CIFAR-10 (32×32 RGB)\")\n",
    "    print(\"  • CNN Backbone: ResNet18 (ImageNet pre-trained, FROZEN)\")\n",
    "    print(\"  • Feature dimension: 512\")\n",
    "    print(\"  • Batch size: 128\")\n",
    "    print(\"  • Patience: 10\")\n",
    "    print(\"  • Seeds: [42, 123, 456]\")\n",
    "    print(\"  • Architecture: CNN(frozen) → 512 → 128 → 10\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # ImageNet normalization (required for pre-trained ResNet)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Load full datasets\n",
    "    full_train_ds = datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                     download=True, transform=transform)\n",
    "    full_test_ds = datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                    download=True, transform=transform)\n",
    "\n",
    "    # Create stratified samples\n",
    "    print(\"\\nCreating stratified samples...\")\n",
    "    t0 = time.time()\n",
    "    train_indices = stratified_sample_from_targets(full_train_ds, n_samples_per_class=1500, seed=42)\n",
    "    test_indices = stratified_sample_from_targets(full_test_ds, n_samples_per_class=300, seed=42)\n",
    "    print(f\"  Sampling took {time.time()-t0:.2f}s\")\n",
    "    \n",
    "    train_ds = Subset(full_train_ds, train_indices)\n",
    "    test_ds = Subset(full_test_ds, test_indices)\n",
    "    \n",
    "    print(f\"  Train samples: {len(train_ds)} (stratified, 1500 per class)\")\n",
    "    print(f\"  Test samples:  {len(test_ds)} (stratified, 300 per class)\")\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128,\n",
    "                              shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_ds, batch_size=256,\n",
    "                             shuffle=False, num_workers=4)\n",
    "\n",
    "    seeds = [42, 123, 456]\n",
    "    all_results = []\n",
    "    frozen_cnn_state = None\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\"SEED {seed}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        set_all_seeds(seed)\n",
    "\n",
    "        print(f\"\\n  Training RealNet-CNN (seed={seed})...\")\n",
    "        real_model = RealNetCNN().to(device)\n",
    "        \n",
    "        # Only optimize the head parameters (CNN is frozen)\n",
    "        real_opt = torch.optim.Adam(real_model.head.parameters(), lr=1e-3)\n",
    "        \n",
    "        result = train_with_early_stopping(\n",
    "            real_model, train_loader, test_loader, real_opt, device,\n",
    "            max_epochs=40, patience=10, name=\"Real-CNN\"\n",
    "        )\n",
    "        \n",
    "        # Count only trainable parameters\n",
    "        trainable_params = sum(p.numel() for p in real_model.head.parameters())\n",
    "        total_params = sum(p.numel() for p in real_model.parameters())\n",
    "        \n",
    "        result[\"trainable_params\"] = trainable_params\n",
    "        result[\"total_params\"] = total_params\n",
    "        result[\"seed\"] = seed\n",
    "        \n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Save frozen CNN state from first seed\n",
    "        if frozen_cnn_state is None:\n",
    "            frozen_cnn_state = real_model.cnn_extractor.state_dict()\n",
    "            print(f\"\\n  → Saved frozen CNN state from seed {seed}\")\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"REALNET-CNN SUMMARY (CIFAR-10)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    accs = [r[\"best_acc\"] for r in all_results]\n",
    "    times = [r[\"time\"] for r in all_results]\n",
    "    epochs = [r[\"epochs\"] for r in all_results]\n",
    "    trainable = all_results[0][\"trainable_params\"]\n",
    "    total = all_results[0][\"total_params\"]\n",
    "    \n",
    "    print(f\"\\nAccuracy:          {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "    print(f\"Time:              {np.mean(times):.1f}s ± {np.std(times):.1f}s\")\n",
    "    print(f\"Epochs:            {np.mean(epochs):.1f} ± {np.std(epochs):.1f}\")\n",
    "    print(f\"Trainable params:  {trainable:,}\")\n",
    "    print(f\"Total params:      {total:,}\")\n",
    "    print(f\"Frozen params:     {total - trainable:,}\")\n",
    "    \n",
    "    print(\"\\nPer-seed results:\")\n",
    "    for r in all_results:\n",
    "        print(f\"  Seed {r['seed']}: acc={r['best_acc']:.4f}, \"\n",
    "              f\"time={r['time']:.1f}s, epochs={r['epochs']}\")\n",
    "\n",
    "    # Save results and frozen CNN\n",
    "    save_dict = {\n",
    "        \"results\": all_results,\n",
    "        \"frozen_cnn_state\": frozen_cnn_state,\n",
    "        \"summary\": {\n",
    "            \"mean_acc\": np.mean(accs),\n",
    "            \"std_acc\": np.std(accs),\n",
    "            \"mean_time\": np.mean(times),\n",
    "            \"trainable_params\": trainable,\n",
    "            \"total_params\": total\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    torch.save(save_dict, \"realnet_cnn_cifar10_results.pt\")\n",
    "    print(f\"\\n✓ Saved results to: realnet_cnn_cifar10_results.pt\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce55e03-3b51-4089-bec4-c12497512f4e",
   "metadata": {},
   "source": [
    "# Quaternion with CNN Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e95731-eb8d-4cb8-a088-93f559d4d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch device: cuda\n",
      "======================================================================\n",
      "BLOCK 2: QuatNet Training with Frozen CNN (CIFAR-10)\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  • Dataset: CIFAR-10 (32×32 RGB)\n",
      "  • CNN Backbone: ResNet18 (FROZEN)\n",
      "  • Batch size: 128\n",
      "  • Patience: 10\n",
      "  • Seeds: [42, 123, 456]\n",
      "  • Architecture: CNN(frozen) → 512 → 128 quats → 32 quats → 10\n",
      "======================================================================\n",
      "\n",
      "Loading frozen CNN from Block 1...\n",
      "✓ Loaded frozen CNN state from realnet_cnn_cifar10_results.pt\n",
      "  CNN frozen with 11,176,512 params\n",
      "\n",
      "Creating stratified samples...\n",
      "  Sampling took 0.00s\n",
      "  Train samples: 15000 (stratified, 1500 per class)\n",
      "  Test samples:  3000 (stratified, 300 per class)\n",
      "\n",
      "======================================================================\n",
      "SEED 42\n",
      "======================================================================\n",
      "\n",
      "  Training QuatNet-CNN (seed=42)...\n",
      "  [Quat-CNN] Epoch  1 | loss=3.2419 | test_acc=0.1780 | time=1.1s\n",
      "  [Quat-CNN] Epoch  2 | loss=2.4684 | test_acc=0.2443 | time=1.9s\n",
      "  [Quat-CNN] Epoch  3 | loss=2.1628 | test_acc=0.2850 | time=2.9s\n",
      "  [Quat-CNN] Epoch  4 | loss=1.9959 | test_acc=0.3163 | time=3.7s\n",
      "  [Quat-CNN] Epoch  5 | loss=1.9119 | test_acc=0.3347 | time=4.7s\n",
      "  [Quat-CNN] Epoch  6 | loss=1.8316 | test_acc=0.3547 | time=5.6s\n",
      "  [Quat-CNN] Epoch  7 | loss=1.7884 | test_acc=0.3693 | time=6.5s\n",
      "  [Quat-CNN] Epoch  8 | loss=1.7576 | test_acc=0.3780 | time=7.4s\n",
      "  [Quat-CNN] Epoch  9 | loss=1.7204 | test_acc=0.3813 | time=8.3s\n",
      "  [Quat-CNN] Epoch 10 | loss=1.6923 | test_acc=0.3883 | time=9.1s\n",
      "  [Quat-CNN] Epoch 11 | loss=1.6742 | test_acc=0.4030 | time=10.0s\n",
      "  [Quat-CNN] Epoch 12 | loss=1.6508 | test_acc=0.3947 | time=10.9s\n",
      "  [Quat-CNN] Epoch 13 | loss=1.6349 | test_acc=0.4003 | time=11.8s\n",
      "  [Quat-CNN] Epoch 14 | loss=1.6168 | test_acc=0.4103 | time=12.7s\n",
      "  [Quat-CNN] Epoch 15 | loss=1.5988 | test_acc=0.4197 | time=13.5s\n",
      "  [Quat-CNN] Epoch 16 | loss=1.5917 | test_acc=0.4220 | time=14.4s\n",
      "  [Quat-CNN] Epoch 17 | loss=1.5816 | test_acc=0.4250 | time=15.3s\n",
      "  [Quat-CNN] Epoch 18 | loss=1.5694 | test_acc=0.4270 | time=16.2s\n",
      "  [Quat-CNN] Epoch 19 | loss=1.5595 | test_acc=0.4307 | time=17.0s\n",
      "  [Quat-CNN] Epoch 20 | loss=1.5481 | test_acc=0.4307 | time=17.9s\n",
      "  [Quat-CNN] Epoch 21 | loss=1.5429 | test_acc=0.4367 | time=18.8s\n",
      "  [Quat-CNN] Epoch 22 | loss=1.5330 | test_acc=0.4367 | time=19.6s\n",
      "  [Quat-CNN] Epoch 23 | loss=1.5234 | test_acc=0.4380 | time=20.5s\n",
      "  [Quat-CNN] Epoch 24 | loss=1.5190 | test_acc=0.4407 | time=21.4s\n",
      "  [Quat-CNN] Epoch 25 | loss=1.5122 | test_acc=0.4423 | time=22.3s\n",
      "  [Quat-CNN] Epoch 26 | loss=1.5081 | test_acc=0.4400 | time=23.3s\n",
      "  [Quat-CNN] Epoch 27 | loss=1.5060 | test_acc=0.4417 | time=24.2s\n",
      "  [Quat-CNN] Epoch 28 | loss=1.5003 | test_acc=0.4423 | time=25.1s\n",
      "  [Quat-CNN] Epoch 29 | loss=1.4882 | test_acc=0.4387 | time=25.9s\n",
      "  [Quat-CNN] Epoch 30 | loss=1.4800 | test_acc=0.4430 | time=26.8s\n",
      "  [Quat-CNN] Epoch 31 | loss=1.4769 | test_acc=0.4403 | time=27.7s\n",
      "  [Quat-CNN] Epoch 32 | loss=1.4666 | test_acc=0.4450 | time=28.6s\n",
      "  [Quat-CNN] Epoch 33 | loss=1.4689 | test_acc=0.4447 | time=29.5s\n",
      "  [Quat-CNN] Epoch 34 | loss=1.4601 | test_acc=0.4513 | time=30.4s\n",
      "  [Quat-CNN] Epoch 35 | loss=1.4569 | test_acc=0.4457 | time=31.3s\n",
      "  [Quat-CNN] Epoch 36 | loss=1.4484 | test_acc=0.4513 | time=32.2s\n",
      "  [Quat-CNN] Epoch 37 | loss=1.4540 | test_acc=0.4450 | time=33.1s\n",
      "  [Quat-CNN] Epoch 38 | loss=1.4485 | test_acc=0.4523 | time=34.0s\n",
      "  [Quat-CNN] Epoch 39 | loss=1.4328 | test_acc=0.4517 | time=34.9s\n",
      "  [Quat-CNN] Epoch 40 | loss=1.4256 | test_acc=0.4510 | time=35.8s\n",
      "\n",
      "======================================================================\n",
      "SEED 123\n",
      "======================================================================\n",
      "\n",
      "  Training QuatNet-CNN (seed=123)...\n",
      "  [Quat-CNN] Epoch  1 | loss=3.1616 | test_acc=0.1777 | time=1.0s\n",
      "  [Quat-CNN] Epoch  2 | loss=2.4344 | test_acc=0.2380 | time=1.8s\n",
      "  [Quat-CNN] Epoch  3 | loss=2.1396 | test_acc=0.2743 | time=2.7s\n",
      "  [Quat-CNN] Epoch  4 | loss=1.9975 | test_acc=0.3187 | time=3.6s\n",
      "  [Quat-CNN] Epoch  5 | loss=1.8990 | test_acc=0.3387 | time=4.6s\n",
      "  [Quat-CNN] Epoch  6 | loss=1.8293 | test_acc=0.3390 | time=5.5s\n",
      "  [Quat-CNN] Epoch  7 | loss=1.7824 | test_acc=0.3597 | time=6.4s\n",
      "  [Quat-CNN] Epoch  8 | loss=1.7430 | test_acc=0.3637 | time=7.4s\n",
      "  [Quat-CNN] Epoch  9 | loss=1.7093 | test_acc=0.3723 | time=8.3s\n",
      "  [Quat-CNN] Epoch 10 | loss=1.6876 | test_acc=0.3837 | time=9.3s\n",
      "  [Quat-CNN] Epoch 11 | loss=1.6631 | test_acc=0.3913 | time=10.2s\n",
      "  [Quat-CNN] Epoch 12 | loss=1.6423 | test_acc=0.3960 | time=11.1s\n",
      "  [Quat-CNN] Epoch 13 | loss=1.6316 | test_acc=0.4037 | time=12.0s\n",
      "  [Quat-CNN] Epoch 14 | loss=1.6135 | test_acc=0.3987 | time=12.9s\n",
      "  [Quat-CNN] Epoch 15 | loss=1.5938 | test_acc=0.4027 | time=13.8s\n",
      "  [Quat-CNN] Epoch 16 | loss=1.5851 | test_acc=0.4160 | time=14.7s\n",
      "  [Quat-CNN] Epoch 17 | loss=1.5783 | test_acc=0.4173 | time=15.6s\n",
      "  [Quat-CNN] Epoch 18 | loss=1.5664 | test_acc=0.4190 | time=16.5s\n",
      "  [Quat-CNN] Epoch 19 | loss=1.5582 | test_acc=0.4150 | time=17.4s\n",
      "  [Quat-CNN] Epoch 20 | loss=1.5439 | test_acc=0.4260 | time=18.2s\n",
      "  [Quat-CNN] Epoch 21 | loss=1.5341 | test_acc=0.4397 | time=19.2s\n",
      "  [Quat-CNN] Epoch 22 | loss=1.5344 | test_acc=0.4280 | time=20.1s\n",
      "  [Quat-CNN] Epoch 23 | loss=1.5210 | test_acc=0.4337 | time=21.0s\n",
      "  [Quat-CNN] Epoch 24 | loss=1.5182 | test_acc=0.4347 | time=21.9s\n",
      "  [Quat-CNN] Epoch 25 | loss=1.5062 | test_acc=0.4350 | time=22.7s\n",
      "  [Quat-CNN] Epoch 26 | loss=1.5001 | test_acc=0.4343 | time=23.6s\n",
      "  [Quat-CNN] Epoch 27 | loss=1.5006 | test_acc=0.4350 | time=24.5s\n",
      "  [Quat-CNN] Epoch 28 | loss=1.4822 | test_acc=0.4403 | time=25.4s\n",
      "  [Quat-CNN] Epoch 29 | loss=1.4834 | test_acc=0.4433 | time=26.2s\n",
      "  [Quat-CNN] Epoch 30 | loss=1.4809 | test_acc=0.4343 | time=27.1s\n",
      "  [Quat-CNN] Epoch 31 | loss=1.4728 | test_acc=0.4357 | time=28.1s\n",
      "  [Quat-CNN] Epoch 32 | loss=1.4639 | test_acc=0.4390 | time=29.0s\n",
      "  [Quat-CNN] Epoch 33 | loss=1.4646 | test_acc=0.4357 | time=29.9s\n",
      "  [Quat-CNN] Epoch 34 | loss=1.4562 | test_acc=0.4420 | time=30.9s\n",
      "  [Quat-CNN] Epoch 35 | loss=1.4560 | test_acc=0.4430 | time=31.8s\n",
      "  [Quat-CNN] Epoch 36 | loss=1.4523 | test_acc=0.4473 | time=32.7s\n",
      "  [Quat-CNN] Epoch 37 | loss=1.4445 | test_acc=0.4393 | time=33.6s\n",
      "  [Quat-CNN] Epoch 38 | loss=1.4442 | test_acc=0.4467 | time=34.4s\n",
      "  [Quat-CNN] Epoch 39 | loss=1.4425 | test_acc=0.4407 | time=35.3s\n",
      "  [Quat-CNN] Epoch 40 | loss=1.4312 | test_acc=0.4387 | time=36.2s\n",
      "\n",
      "======================================================================\n",
      "SEED 456\n",
      "======================================================================\n",
      "\n",
      "  Training QuatNet-CNN (seed=456)...\n",
      "  [Quat-CNN] Epoch  1 | loss=3.2016 | test_acc=0.1670 | time=0.9s\n",
      "  [Quat-CNN] Epoch  2 | loss=2.4423 | test_acc=0.2377 | time=1.9s\n",
      "  [Quat-CNN] Epoch  3 | loss=2.1631 | test_acc=0.2810 | time=2.8s\n",
      "  [Quat-CNN] Epoch  4 | loss=1.9958 | test_acc=0.3043 | time=3.8s\n",
      "  [Quat-CNN] Epoch  5 | loss=1.9108 | test_acc=0.3283 | time=4.7s\n",
      "  [Quat-CNN] Epoch  6 | loss=1.8422 | test_acc=0.3450 | time=5.7s\n",
      "  [Quat-CNN] Epoch  7 | loss=1.7870 | test_acc=0.3660 | time=6.6s\n",
      "  [Quat-CNN] Epoch  8 | loss=1.7567 | test_acc=0.3690 | time=7.6s\n",
      "  [Quat-CNN] Epoch  9 | loss=1.7206 | test_acc=0.3840 | time=8.6s\n",
      "  [Quat-CNN] Epoch 10 | loss=1.6985 | test_acc=0.3973 | time=9.5s\n",
      "  [Quat-CNN] Epoch 11 | loss=1.6738 | test_acc=0.3933 | time=10.4s\n",
      "  [Quat-CNN] Epoch 12 | loss=1.6539 | test_acc=0.4040 | time=11.3s\n",
      "  [Quat-CNN] Epoch 13 | loss=1.6460 | test_acc=0.4103 | time=12.2s\n",
      "  [Quat-CNN] Epoch 14 | loss=1.6212 | test_acc=0.4133 | time=13.1s\n",
      "  [Quat-CNN] Epoch 15 | loss=1.6085 | test_acc=0.4117 | time=14.0s\n",
      "  [Quat-CNN] Epoch 16 | loss=1.5959 | test_acc=0.4177 | time=14.9s\n",
      "  [Quat-CNN] Epoch 17 | loss=1.5840 | test_acc=0.4220 | time=15.8s\n",
      "  [Quat-CNN] Epoch 18 | loss=1.5704 | test_acc=0.4223 | time=16.7s\n",
      "  [Quat-CNN] Epoch 19 | loss=1.5602 | test_acc=0.4270 | time=17.6s\n",
      "  [Quat-CNN] Epoch 20 | loss=1.5518 | test_acc=0.4237 | time=18.6s\n",
      "  [Quat-CNN] Epoch 21 | loss=1.5466 | test_acc=0.4253 | time=19.5s\n",
      "  [Quat-CNN] Epoch 22 | loss=1.5388 | test_acc=0.4277 | time=20.4s\n",
      "  [Quat-CNN] Epoch 23 | loss=1.5255 | test_acc=0.4290 | time=21.2s\n",
      "  [Quat-CNN] Epoch 24 | loss=1.5132 | test_acc=0.4327 | time=22.1s\n",
      "  [Quat-CNN] Epoch 25 | loss=1.5158 | test_acc=0.4377 | time=23.0s\n",
      "  [Quat-CNN] Epoch 26 | loss=1.5116 | test_acc=0.4363 | time=23.9s\n",
      "  [Quat-CNN] Epoch 27 | loss=1.4932 | test_acc=0.4407 | time=24.8s\n",
      "  [Quat-CNN] Epoch 28 | loss=1.4926 | test_acc=0.4343 | time=25.7s\n",
      "  [Quat-CNN] Epoch 29 | loss=1.4902 | test_acc=0.4393 | time=26.6s\n",
      "  [Quat-CNN] Epoch 30 | loss=1.4826 | test_acc=0.4437 | time=27.4s\n",
      "  [Quat-CNN] Epoch 31 | loss=1.4745 | test_acc=0.4443 | time=28.3s\n",
      "  [Quat-CNN] Epoch 32 | loss=1.4725 | test_acc=0.4437 | time=29.2s\n",
      "  [Quat-CNN] Epoch 33 | loss=1.4749 | test_acc=0.4423 | time=30.1s\n",
      "  [Quat-CNN] Epoch 34 | loss=1.4634 | test_acc=0.4390 | time=30.9s\n",
      "  [Quat-CNN] Epoch 35 | loss=1.4600 | test_acc=0.4450 | time=31.8s\n",
      "  [Quat-CNN] Epoch 36 | loss=1.4591 | test_acc=0.4507 | time=32.7s\n",
      "  [Quat-CNN] Epoch 37 | loss=1.4494 | test_acc=0.4413 | time=33.6s\n",
      "  [Quat-CNN] Epoch 38 | loss=1.4380 | test_acc=0.4433 | time=34.5s\n",
      "  [Quat-CNN] Epoch 39 | loss=1.4419 | test_acc=0.4440 | time=35.3s\n",
      "  [Quat-CNN] Epoch 40 | loss=1.4377 | test_acc=0.4567 | time=36.2s\n",
      "\n",
      "======================================================================\n",
      "QUATNET-CNN SUMMARY (CIFAR-10)\n",
      "======================================================================\n",
      "\n",
      "Accuracy:          0.4521 ± 0.0038\n",
      "Time:              36.1s ± 0.2s\n",
      "Epochs:            40.0 ± 0.0\n",
      "Trainable params:  17,832\n",
      "Total params:      11,194,344\n",
      "Frozen params:     11,176,512\n",
      "\n",
      "Per-seed results:\n",
      "  Seed 42: acc=0.4523, time=35.8s, epochs=40\n",
      "  Seed 123: acc=0.4473, time=36.2s, epochs=40\n",
      "  Seed 456: acc=0.4567, time=36.2s, epochs=40\n",
      "\n",
      "✓ Saved results to: quatnet_cnn_cifar10_results.pt\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Block 2: QuatNet Training with Frozen CNN (CIFAR-10)\n",
    "====================================================\n",
    "Loads frozen CNN from Block 1 and trains quaternion head on 3 seeds.\n",
    "\n",
    "Requirements:\n",
    "- realnet_cnn_cifar10_results.pt (from Block 1)\n",
    "\n",
    "Outputs:\n",
    "- quatnet_cnn_cifar10_results.pt: Contains quaternion head results\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using PyTorch device: {device}\")\n",
    "\n",
    "# ============================================\n",
    "# Comprehensive seed setting for reproducibility\n",
    "# ============================================\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    \"\"\"Set seeds for all RNG sources for reproducibility\"\"\"\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    # Python\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # PyTorch deterministic mode\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # CuPy (if available)\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        cp.random.seed(seed)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # PennyLane (if available)\n",
    "    try:\n",
    "        import pennylane as qml\n",
    "        qml.numpy.random.seed(seed)\n",
    "    except (ImportError, AttributeError):\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Quaternion utilities (PyTorch tensors)\n",
    "# ============================================\n",
    "\n",
    "def q_normalize(q):\n",
    "    norm = torch.linalg.norm(q, dim=-1, keepdim=True) + 1e-8\n",
    "    return q / norm\n",
    "\n",
    "def q_conj(q):\n",
    "    w, x, y, z = torch.unbind(q, dim=-1)\n",
    "    return torch.stack([w, -x, -y, -z], dim=-1)\n",
    "\n",
    "def q_mul(a, b):\n",
    "    \"\"\"Hamilton product of two quaternions\"\"\"\n",
    "    aw, ax, ay, az = torch.unbind(a, dim=-1)\n",
    "    bw, bx, by, bz = torch.unbind(b, dim=-1)\n",
    "\n",
    "    w = aw * bw - ax * bx - ay * by - az * bz\n",
    "    x = aw * bx + ax * bw + ay * bz - az * by\n",
    "    y = aw * by - ax * bz + ay * bw + az * bx\n",
    "    z = aw * bz + ax * by - ay * bx + az * bw\n",
    "\n",
    "    return torch.stack([w, x, y, z], dim=-1)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Frozen CNN Feature Extractor (from Block 1)\n",
    "# ============================================\n",
    "\n",
    "class FrozenCNNExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Frozen ResNet18 feature extractor.\n",
    "    Outputs 512-dimensional features from penultimate layer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        resnet = resnet18(weights=weights)\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.eval()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            features = self.features(x)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        return features\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Quaternion Head and Network\n",
    "# ============================================\n",
    "\n",
    "class QuaternionLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \"\"\"\n",
    "        in_features, out_features are in \"quaternion units\".\n",
    "        Internally weight: (out_features, in_features, 4)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features, 4))\n",
    "        self.bias = nn.Parameter(torch.empty(out_features, 4))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.weight, mean=0.0, std=0.1)\n",
    "        with torch.no_grad():\n",
    "            self.weight[:] = q_normalize(self.weight)\n",
    "            nn.init.constant_(self.bias[..., 0], 1.0)\n",
    "            nn.init.constant_(self.bias[..., 1:], 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, in_features, 4)\n",
    "        Returns: (B, out_features, 4)\n",
    "        \"\"\"\n",
    "        w = self.weight.unsqueeze(0)\n",
    "        x_exp = x.unsqueeze(1)\n",
    "        prod = q_mul(w, x_exp)\n",
    "        out = prod.sum(dim=2) + self.bias\n",
    "        return out\n",
    "\n",
    "\n",
    "class QuatHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Quaternion head: 128 quats → 32 quats → 10 quats → 10 logits.\n",
    "    Input: 512 real features → 128 quaternions\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=512, num_classes=10):\n",
    "        super().__init__()\n",
    "        # 512 real features = 128 quaternions (512/4)\n",
    "        self.input_quats = input_dim // 4\n",
    "        self.quat_fc1 = QuaternionLinear(self.input_quats, 32)\n",
    "        self.quat_fc2 = QuaternionLinear(32, num_classes)\n",
    "\n",
    "    def real_to_quat(self, x):\n",
    "        \"\"\"Convert 512 real features to 128 quaternions\"\"\"\n",
    "        B = x.size(0)\n",
    "        return x.view(B, self.input_quats, 4)\n",
    "\n",
    "    def quat_to_real(self, q):\n",
    "        \"\"\"Extract real part of quaternions for classification\"\"\"\n",
    "        return q[..., 0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        q_in = self.real_to_quat(x)\n",
    "        hq = self.quat_fc1(q_in)\n",
    "        hq = q_normalize(hq)\n",
    "        hq = torch.tanh(hq)\n",
    "        q_out = self.quat_fc2(hq)\n",
    "        logits = self.quat_to_real(q_out)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class QuatNetCNN(nn.Module):\n",
    "    \"\"\"Complete Quaternion network: Frozen CNN + QuatHead\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_extractor = FrozenCNNExtractor()\n",
    "        self.head = QuatHead(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.cnn_extractor(x)\n",
    "        return self.head(features)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Training and Evaluation\n",
    "# ============================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device, show_progress=False):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total_samples += x.size(0)\n",
    "\n",
    "        if show_progress and batch_idx % 50 == 0:\n",
    "            print(f\"    Batch {batch_idx}/{len(loader)}, samples: {total_samples}\", end=\"\\r\")\n",
    "\n",
    "    if show_progress:\n",
    "        print()\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "def train_with_early_stopping(model, train_loader, test_loader, optimizer,\n",
    "                              device, max_epochs=40, patience=10, name=\"Model\"):\n",
    "    if isinstance(device, str):\n",
    "        device = torch.device(device)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    start = time.time()\n",
    "    last_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        loss = train_one_epoch(model, train_loader, optimizer, device, show_progress=False)\n",
    "        acc = evaluate(model, test_loader, device)\n",
    "        last_acc = acc\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"  [{name}] Epoch {epoch:2d} | loss={loss:.4f} \"\n",
    "              f\"| test_acc={acc:.4f} | time={elapsed:.1f}s\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"  [{name}] Early stop at epoch {epoch} \"\n",
    "                  f\"(no improvement for {patience} epochs)\")\n",
    "            break\n",
    "\n",
    "    total_time = time.time() - start\n",
    "    return {\n",
    "        \"best_acc\": best_acc,\n",
    "        \"final_acc\": last_acc,\n",
    "        \"time\": total_time,\n",
    "        \"epochs\": epoch,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Data utilities\n",
    "# ============================================\n",
    "\n",
    "def stratified_sample_from_targets(dataset, n_samples_per_class, seed=42):\n",
    "    \"\"\"\n",
    "    Create a stratified sample with n_samples_per_class from each class.\n",
    "    Uses dataset.targets directly - NO image loading during sampling.\n",
    "    \"\"\"\n",
    "    if hasattr(dataset, 'targets'):\n",
    "        targets = np.array(dataset.targets)\n",
    "    else:\n",
    "        targets = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "    \n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    sampled_indices = []\n",
    "    for c in range(10):\n",
    "        idx_c = np.where(targets == c)[0]\n",
    "        k = min(n_samples_per_class, len(idx_c))\n",
    "        selected = rng.choice(idx_c, size=k, replace=False).tolist()\n",
    "        sampled_indices.extend(selected)\n",
    "    \n",
    "    rng.shuffle(sampled_indices)\n",
    "    return sampled_indices\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Main\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BLOCK 2: QuatNet Training with Frozen CNN (CIFAR-10)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nConfiguration:\")\n",
    "    print(\"  • Dataset: CIFAR-10 (32×32 RGB)\")\n",
    "    print(\"  • CNN Backbone: ResNet18 (FROZEN)\")\n",
    "    print(\"  • Batch size: 128\")\n",
    "    print(\"  • Patience: 10\")\n",
    "    print(\"  • Seeds: [42, 123, 456]\")\n",
    "    print(\"  • Architecture: CNN(frozen) → 512 → 128 quats → 32 quats → 10\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Load frozen CNN from Block 1\n",
    "    print(\"\\nLoading frozen CNN from Block 1...\")\n",
    "    try:\n",
    "        realnet_data = torch.load(\"realnet_cnn_cifar10_results.pt\", weights_only=False)\n",
    "        frozen_cnn_state = realnet_data[\"frozen_cnn_state\"]\n",
    "        print(\"✓ Loaded frozen CNN state from realnet_cnn_cifar10_results.pt\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"✗ ERROR: realnet_cnn_cifar10_results.pt not found!\")\n",
    "        print(\"  Run Block 1 first to train RealNet and save frozen CNN.\")\n",
    "        return\n",
    "\n",
    "    # Create frozen CNN\n",
    "    shared_cnn = FrozenCNNExtractor().to(device)\n",
    "    shared_cnn.load_state_dict(frozen_cnn_state)\n",
    "    for p in shared_cnn.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    cnn_params = sum(p.numel() for p in shared_cnn.parameters())\n",
    "    print(f\"  CNN frozen with {cnn_params:,} params\")\n",
    "\n",
    "    # Load data - ImageNet normalization (required for pre-trained CNN)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    full_train_ds = datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                     download=True, transform=transform)\n",
    "    full_test_ds = datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                    download=True, transform=transform)\n",
    "\n",
    "    # Create stratified samples\n",
    "    print(\"\\nCreating stratified samples...\")\n",
    "    t0 = time.time()\n",
    "    train_indices = stratified_sample_from_targets(full_train_ds, n_samples_per_class=1500, seed=42)\n",
    "    test_indices = stratified_sample_from_targets(full_test_ds, n_samples_per_class=300, seed=42)\n",
    "    print(f\"  Sampling took {time.time()-t0:.2f}s\")\n",
    "    \n",
    "    train_ds = Subset(full_train_ds, train_indices)\n",
    "    test_ds = Subset(full_test_ds, test_indices)\n",
    "    \n",
    "    print(f\"  Train samples: {len(train_ds)} (stratified, 1500 per class)\")\n",
    "    print(f\"  Test samples:  {len(test_ds)} (stratified, 300 per class)\")\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=128,\n",
    "                              shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_ds, batch_size=256,\n",
    "                             shuffle=False, num_workers=4)\n",
    "\n",
    "    seeds = [42, 123, 456]\n",
    "    all_results = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\"SEED {seed}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        set_all_seeds(seed)\n",
    "\n",
    "        print(f\"\\n  Training QuatNet-CNN (seed={seed})...\")\n",
    "        quat_model = QuatNetCNN().to(device)\n",
    "        quat_model.cnn_extractor = shared_cnn  # Use frozen CNN\n",
    "        \n",
    "        # Only optimize head parameters\n",
    "        quat_opt = torch.optim.Adam(quat_model.head.parameters(), lr=1e-3)\n",
    "        \n",
    "        result = train_with_early_stopping(\n",
    "            quat_model, train_loader, test_loader, quat_opt, device,\n",
    "            max_epochs=40, patience=10, name=\"Quat-CNN\"\n",
    "        )\n",
    "        \n",
    "        trainable_params = sum(p.numel() for p in quat_model.head.parameters())\n",
    "        total_params = sum(p.numel() for p in quat_model.parameters())\n",
    "        \n",
    "        result[\"trainable_params\"] = trainable_params\n",
    "        result[\"total_params\"] = total_params\n",
    "        result[\"seed\"] = seed\n",
    "        \n",
    "        all_results.append(result)\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"QUATNET-CNN SUMMARY (CIFAR-10)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    accs = [r[\"best_acc\"] for r in all_results]\n",
    "    times = [r[\"time\"] for r in all_results]\n",
    "    epochs = [r[\"epochs\"] for r in all_results]\n",
    "    trainable = all_results[0][\"trainable_params\"]\n",
    "    total = all_results[0][\"total_params\"]\n",
    "    \n",
    "    print(f\"\\nAccuracy:          {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "    print(f\"Time:              {np.mean(times):.1f}s ± {np.std(times):.1f}s\")\n",
    "    print(f\"Epochs:            {np.mean(epochs):.1f} ± {np.std(epochs):.1f}\")\n",
    "    print(f\"Trainable params:  {trainable:,}\")\n",
    "    print(f\"Total params:      {total:,}\")\n",
    "    print(f\"Frozen params:     {total - trainable:,}\")\n",
    "    \n",
    "    print(\"\\nPer-seed results:\")\n",
    "    for r in all_results:\n",
    "        print(f\"  Seed {r['seed']}: acc={r['best_acc']:.4f}, \"\n",
    "              f\"time={r['time']:.1f}s, epochs={r['epochs']}\")\n",
    "\n",
    "    # Save results\n",
    "    save_dict = {\n",
    "        \"results\": all_results,\n",
    "        \"summary\": {\n",
    "            \"mean_acc\": np.mean(accs),\n",
    "            \"std_acc\": np.std(accs),\n",
    "            \"mean_time\": np.mean(times),\n",
    "            \"trainable_params\": trainable,\n",
    "            \"total_params\": total\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    torch.save(save_dict, \"quatnet_cnn_cifar10_results.pt\")\n",
    "    print(f\"\\n✓ Saved results to: quatnet_cnn_cifar10_results.pt\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090f177-ae10-44b1-b9cd-ef3688ab0cf6",
   "metadata": {},
   "source": [
    "# Quantum No Ent CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1931b071-0ca8-4b64-a4ef-b85ccff03c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using lightning.gpu device\n",
      "Using PyTorch device: cuda\n",
      "======================================================================\n",
      "BLOCK 3: Quantum (NO Entanglement) Training with Frozen CNN (CIFAR-10)\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  • Dataset: CIFAR-10 (32×32 RGB)\n",
      "  • CNN Backbone: ResNet18 (FROZEN)\n",
      "  • Batch size: 32\n",
      "  • Patience: 10\n",
      "  • Max epochs: 200\n",
      "  • Seeds: [42, 123, 456]\n",
      "  • Architecture: CNN(frozen) → 512 → 8 qubits (3 layers, NO ent) → 10\n",
      "  • Quantum device: lightning.gpu\n",
      "======================================================================\n",
      "\n",
      "Loading frozen CNN from Block 1...\n",
      "✓ Loaded frozen CNN state from realnet_cnn_cifar10_results.pt\n",
      "  CNN frozen with 11,176,512 params\n",
      "\n",
      "Creating stratified samples...\n",
      "  Sampling took 0.00s\n",
      "  Train samples: 15000 (stratified, 1500 per class)\n",
      "  Test samples:  3000 (stratified, 300 per class)\n",
      "\n",
      "======================================================================\n",
      "SEED 42\n",
      "======================================================================\n",
      "\n",
      "  Training QuantumNet-CNN (NO entanglement, seed=42)...\n",
      "  [QuantumNoEnt-CNN] Epoch 1/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  1 | loss=2.1942 | test_acc=0.2683 | time=1263.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 2/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  2 | loss=2.0082 | test_acc=0.2510 | time=2518.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 3/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  3 | loss=1.9335 | test_acc=0.3020 | time=3783.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 4/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  4 | loss=1.8985 | test_acc=0.3243 | time=5043.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 5/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  5 | loss=1.8671 | test_acc=0.3467 | time=6307.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 6/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  6 | loss=1.8427 | test_acc=0.3507 | time=7601.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 7/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  7 | loss=1.8199 | test_acc=0.3640 | time=8936.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 8/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  8 | loss=1.8050 | test_acc=0.3713 | time=10264.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 9/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  9 | loss=1.7955 | test_acc=0.3357 | time=11571.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 10/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 10 | loss=1.7925 | test_acc=0.3753 | time=12865.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 11/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 11 | loss=1.7625 | test_acc=0.3630 | time=14129.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 12/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 12 | loss=1.7392 | test_acc=0.3787 | time=15399.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 13/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 13 | loss=1.7487 | test_acc=0.3880 | time=16755.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 14/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 14 | loss=1.7369 | test_acc=0.3880 | time=18171.0s\n",
      "  [QuantumNoEnt-CNN] Epoch 15/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 15 | loss=1.7384 | test_acc=0.3857 | time=19569.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 16/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 16 | loss=1.7192 | test_acc=0.3957 | time=20961.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 17/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 17 | loss=1.7202 | test_acc=0.4103 | time=22369.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 18/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 18 | loss=1.7026 | test_acc=0.3663 | time=23736.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 19/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 19 | loss=1.6950 | test_acc=0.4030 | time=25127.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 20/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 20 | loss=1.6977 | test_acc=0.3897 | time=26507.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 21/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 21 | loss=1.6814 | test_acc=0.4047 | time=27884.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 22/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 22 | loss=1.6797 | test_acc=0.4097 | time=29269.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 23/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 23 | loss=1.6757 | test_acc=0.4077 | time=30608.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 24/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 24 | loss=1.6732 | test_acc=0.4177 | time=31982.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 25/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 25 | loss=1.6676 | test_acc=0.4170 | time=33369.0s\n",
      "  [QuantumNoEnt-CNN] Epoch 26/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 26 | loss=1.6571 | test_acc=0.4143 | time=34761.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 27/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 27 | loss=1.6630 | test_acc=0.4233 | time=36143.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 28/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 28 | loss=1.6520 | test_acc=0.4140 | time=37505.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 29/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 29 | loss=1.6452 | test_acc=0.4047 | time=38870.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 30/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 30 | loss=1.6567 | test_acc=0.4303 | time=40303.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 31/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 31 | loss=1.6505 | test_acc=0.4183 | time=41739.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 32/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 32 | loss=1.6516 | test_acc=0.4180 | time=43148.0s\n",
      "  [QuantumNoEnt-CNN] Epoch 33/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 33 | loss=1.6584 | test_acc=0.4283 | time=44557.0s\n",
      "  [QuantumNoEnt-CNN] Epoch 34/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 34 | loss=1.6436 | test_acc=0.4293 | time=45931.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 35/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 35 | loss=1.6503 | test_acc=0.4073 | time=47316.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 36/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 36 | loss=1.6480 | test_acc=0.4150 | time=48715.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 37/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 37 | loss=1.6454 | test_acc=0.4120 | time=50106.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 38/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 38 | loss=1.6466 | test_acc=0.4187 | time=51482.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 39/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 39 | loss=1.6418 | test_acc=0.4263 | time=52859.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 40/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 40 | loss=1.6466 | test_acc=0.4193 | time=54249.7s\n",
      "  [QuantumNoEnt-CNN] Early stop at epoch 40 (no improvement for 10 epochs)\n",
      "\n",
      "======================================================================\n",
      "SEED 123\n",
      "======================================================================\n",
      "\n",
      "  Training QuantumNet-CNN (NO entanglement, seed=123)...\n",
      "  [QuantumNoEnt-CNN] Epoch 1/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  1 | loss=2.2596 | test_acc=0.1887 | time=1379.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 2/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  2 | loss=2.0763 | test_acc=0.2627 | time=2777.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 3/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  3 | loss=1.9964 | test_acc=0.2737 | time=4158.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 4/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  4 | loss=1.9509 | test_acc=0.2987 | time=5531.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 5/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  5 | loss=1.9205 | test_acc=0.3090 | time=6900.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 6/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  6 | loss=1.8913 | test_acc=0.3060 | time=8304.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 7/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  7 | loss=1.8820 | test_acc=0.3363 | time=9693.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 8/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  8 | loss=1.8777 | test_acc=0.3317 | time=11097.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 9/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  9 | loss=1.8544 | test_acc=0.3357 | time=12499.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 10/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 10 | loss=1.8465 | test_acc=0.3337 | time=13871.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 11/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 11 | loss=1.8259 | test_acc=0.3547 | time=15266.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 12/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 12 | loss=1.8235 | test_acc=0.3620 | time=16655.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 13/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 13 | loss=1.8004 | test_acc=0.3650 | time=18043.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 14/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 14 | loss=1.7977 | test_acc=0.3637 | time=19441.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 15/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 15 | loss=1.7729 | test_acc=0.3687 | time=20817.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 16/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 16 | loss=1.7681 | test_acc=0.3750 | time=22203.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 17/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 17 | loss=1.7607 | test_acc=0.3707 | time=23575.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 18/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 18 | loss=1.7605 | test_acc=0.3787 | time=24939.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 19/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 19 | loss=1.7538 | test_acc=0.3763 | time=26270.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 20/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 20 | loss=1.7450 | test_acc=0.3793 | time=27537.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 21/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 21 | loss=1.7379 | test_acc=0.3783 | time=28799.0s\n",
      "  [QuantumNoEnt-CNN] Epoch 22/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 22 | loss=1.7347 | test_acc=0.3693 | time=30075.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 23/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 23 | loss=1.7237 | test_acc=0.3800 | time=31370.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 24/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 24 | loss=1.7209 | test_acc=0.3783 | time=32666.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 25/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 25 | loss=1.7091 | test_acc=0.3963 | time=33941.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 26/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 26 | loss=1.7012 | test_acc=0.3837 | time=35240.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 27/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 27 | loss=1.7137 | test_acc=0.3933 | time=36552.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 28/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 28 | loss=1.6964 | test_acc=0.3850 | time=37860.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 29/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 29 | loss=1.7001 | test_acc=0.4053 | time=39156.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 30/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 30 | loss=1.7064 | test_acc=0.4000 | time=40512.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 31/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 31 | loss=1.7037 | test_acc=0.4040 | time=41828.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 32/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 32 | loss=1.6911 | test_acc=0.4090 | time=43169.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 33/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 33 | loss=1.6889 | test_acc=0.3887 | time=44510.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 34/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 34 | loss=1.6960 | test_acc=0.3920 | time=45810.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 35/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 35 | loss=1.6967 | test_acc=0.4013 | time=47115.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 36/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 36 | loss=1.6848 | test_acc=0.4047 | time=48395.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 37/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 37 | loss=1.6796 | test_acc=0.3927 | time=49680.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 38/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 38 | loss=1.6803 | test_acc=0.4003 | time=51000.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 39/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 39 | loss=1.6936 | test_acc=0.3920 | time=52333.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 40/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 40 | loss=1.6774 | test_acc=0.4033 | time=53616.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 41/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 41 | loss=1.6670 | test_acc=0.4030 | time=54972.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 42/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 42 | loss=1.6809 | test_acc=0.4023 | time=56316.3s\n",
      "  [QuantumNoEnt-CNN] Early stop at epoch 42 (no improvement for 10 epochs)\n",
      "\n",
      "======================================================================\n",
      "SEED 456\n",
      "======================================================================\n",
      "\n",
      "  Training QuantumNet-CNN (NO entanglement, seed=456)...\n",
      "  [QuantumNoEnt-CNN] Epoch 1/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  1 | loss=2.1742 | test_acc=0.2463 | time=1309.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 2/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  2 | loss=2.0078 | test_acc=0.2923 | time=2686.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 3/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  3 | loss=1.9533 | test_acc=0.3140 | time=4057.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 4/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  4 | loss=1.9143 | test_acc=0.3223 | time=5353.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 5/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  5 | loss=1.8723 | test_acc=0.3207 | time=6671.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 6/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  6 | loss=1.8743 | test_acc=0.3270 | time=7977.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 7/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  7 | loss=1.8485 | test_acc=0.3183 | time=9292.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 8/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  8 | loss=1.8295 | test_acc=0.3243 | time=10609.0s\n",
      "  [QuantumNoEnt-CNN] Epoch 9/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch  9 | loss=1.8278 | test_acc=0.3267 | time=11940.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 10/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 10 | loss=1.8058 | test_acc=0.3487 | time=13309.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 11/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 11 | loss=1.7990 | test_acc=0.3713 | time=14686.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 12/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 12 | loss=1.7895 | test_acc=0.3487 | time=16003.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 13/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 13 | loss=1.7812 | test_acc=0.3457 | time=17349.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 14/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 14 | loss=1.7727 | test_acc=0.3793 | time=18699.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 15/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 15 | loss=1.7555 | test_acc=0.3840 | time=20025.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 16/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 16 | loss=1.7614 | test_acc=0.3803 | time=21398.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 17/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 17 | loss=1.7560 | test_acc=0.3783 | time=22758.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 18/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 18 | loss=1.7447 | test_acc=0.3697 | time=24059.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 19/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 19 | loss=1.7508 | test_acc=0.3967 | time=25363.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 20/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 20 | loss=1.7474 | test_acc=0.3803 | time=26640.0s\n",
      "  [QuantumNoEnt-CNN] Epoch 21/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 21 | loss=1.7433 | test_acc=0.3957 | time=27955.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 22/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 22 | loss=1.7348 | test_acc=0.3817 | time=29309.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 23/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 23 | loss=1.7356 | test_acc=0.3920 | time=30629.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 24/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 24 | loss=1.7306 | test_acc=0.3947 | time=31913.0s\n",
      "  [QuantumNoEnt-CNN] Epoch 25/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 25 | loss=1.7264 | test_acc=0.3883 | time=33229.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 26/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 26 | loss=1.7372 | test_acc=0.3947 | time=34512.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 27/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 27 | loss=1.7194 | test_acc=0.3947 | time=35823.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 28/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 28 | loss=1.7351 | test_acc=0.3880 | time=37091.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 29/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 29 | loss=1.7235 | test_acc=0.4027 | time=38345.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 30/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 30 | loss=1.7261 | test_acc=0.3860 | time=39628.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 31/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 31 | loss=1.7104 | test_acc=0.3800 | time=40921.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 32/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 32 | loss=1.7163 | test_acc=0.3877 | time=42217.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 33/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 33 | loss=1.7310 | test_acc=0.3937 | time=43489.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 34/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 34 | loss=1.7146 | test_acc=0.3827 | time=44792.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 35/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 35 | loss=1.7178 | test_acc=0.3963 | time=46046.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 36/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 36 | loss=1.7108 | test_acc=0.3933 | time=47330.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 37/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 37 | loss=1.7149 | test_acc=0.4057 | time=48611.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 38/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 38 | loss=1.7144 | test_acc=0.3797 | time=49872.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 39/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 39 | loss=1.7215 | test_acc=0.3993 | time=51152.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 40/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 40 | loss=1.7192 | test_acc=0.3903 | time=52438.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 41/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 41 | loss=1.7158 | test_acc=0.4053 | time=53743.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 42/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 42 | loss=1.7042 | test_acc=0.3963 | time=55008.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 43/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 43 | loss=1.7005 | test_acc=0.3997 | time=56321.3s\n",
      "  [QuantumNoEnt-CNN] Epoch 44/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 44 | loss=1.7050 | test_acc=0.4090 | time=57601.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 45/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 45 | loss=1.7089 | test_acc=0.3890 | time=58892.0s\n",
      "  [QuantumNoEnt-CNN] Epoch 46/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 46 | loss=1.7035 | test_acc=0.3947 | time=60187.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 47/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 47 | loss=1.6959 | test_acc=0.3993 | time=61466.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 48/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 48 | loss=1.6972 | test_acc=0.3947 | time=62790.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 49/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 49 | loss=1.6892 | test_acc=0.4007 | time=64088.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 50/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 50 | loss=1.7033 | test_acc=0.3880 | time=65391.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 51/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 51 | loss=1.6937 | test_acc=0.4083 | time=66715.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 52/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 52 | loss=1.6941 | test_acc=0.3957 | time=68007.2s\n",
      "  [QuantumNoEnt-CNN] Epoch 53/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 53 | loss=1.6930 | test_acc=0.4037 | time=69309.0s\n",
      "  [QuantumNoEnt-CNN] Epoch 54/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 54 | loss=1.7045 | test_acc=0.4120 | time=70607.4s\n",
      "  [QuantumNoEnt-CNN] Epoch 55/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 55 | loss=1.6894 | test_acc=0.4013 | time=71886.9s\n",
      "  [QuantumNoEnt-CNN] Epoch 56/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 56 | loss=1.6918 | test_acc=0.3730 | time=73192.8s\n",
      "  [QuantumNoEnt-CNN] Epoch 57/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 57 | loss=1.6959 | test_acc=0.3967 | time=74513.5s\n",
      "  [QuantumNoEnt-CNN] Epoch 58/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 58 | loss=1.6938 | test_acc=0.3973 | time=75855.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 59/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 59 | loss=1.6840 | test_acc=0.3793 | time=77106.6s\n",
      "  [QuantumNoEnt-CNN] Epoch 60/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 60 | loss=1.6940 | test_acc=0.3953 | time=78395.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 61/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 61 | loss=1.6997 | test_acc=0.4020 | time=79733.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 62/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 62 | loss=1.6885 | test_acc=0.3800 | time=81080.1s\n",
      "  [QuantumNoEnt-CNN] Epoch 63/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 63 | loss=1.6972 | test_acc=0.3977 | time=82371.7s\n",
      "  [QuantumNoEnt-CNN] Epoch 64/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumNoEnt-CNN] Epoch 64 | loss=1.6986 | test_acc=0.3917 | time=83651.7s\n",
      "  [QuantumNoEnt-CNN] Early stop at epoch 64 (no improvement for 10 epochs)\n",
      "\n",
      "======================================================================\n",
      "QUANTUM (NO ENTANGLEMENT) + CNN SUMMARY (CIFAR-10)\n",
      "======================================================================\n",
      "\n",
      "Accuracy:          0.4171 ± 0.0094\n",
      "Time:              64739.2s ± 13399.7s\n",
      "Epochs:            48.7 ± 10.9\n",
      "Trainable params:  4,282\n",
      "Total params:      11,180,794\n",
      "Frozen params:     11,176,512\n",
      "\n",
      "Per-seed results:\n",
      "  Seed 42: acc=0.4303, time=54249.7s, epochs=40\n",
      "  Seed 123: acc=0.4090, time=56316.3s, epochs=42\n",
      "  Seed 456: acc=0.4120, time=83651.7s, epochs=64\n",
      "\n",
      "✓ Saved results to: quantum_noent_cnn_cifar10_results.pt\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Block 3: Quantum (No Entanglement) Training with Frozen CNN (CIFAR-10)\n",
    "=======================================================================\n",
    "Loads frozen CNN from Block 1 and trains quantum head WITHOUT entanglement.\n",
    "Uses Lightning-GPU acceleration.\n",
    "\n",
    "Requirements:\n",
    "- realnet_cnn_cifar10_results.pt (from Block 1)\n",
    "- pennylane, pennylane-lightning-gpu\n",
    "\n",
    "Outputs:\n",
    "- quantum_noent_cnn_cifar10_results.pt: Contains quantum (no ent) results\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "try:\n",
    "    import pennylane as qml\n",
    "    QUANTUM_DEVICE = \"lightning.gpu\"\n",
    "    PENNYLANE_AVAILABLE = True\n",
    "    print(\"✓ Using lightning.gpu device\")\n",
    "except ImportError:\n",
    "    PENNYLANE_AVAILABLE = False\n",
    "    print(\"✗ PennyLane not installed\")\n",
    "    exit(1)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using PyTorch device: {device}\")\n",
    "\n",
    "# ============================================\n",
    "# Comprehensive seed setting for reproducibility\n",
    "# ============================================\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    \"\"\"Set seeds for all RNG sources for reproducibility\"\"\"\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    # Python\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # PyTorch deterministic mode\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # CuPy (if available)\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        cp.random.seed(seed)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # PennyLane (if available)\n",
    "    try:\n",
    "        import pennylane as qml\n",
    "        qml.numpy.random.seed(seed)\n",
    "    except (ImportError, AttributeError):\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Frozen CNN Feature Extractor (from Block 1)\n",
    "# ============================================\n",
    "\n",
    "class FrozenCNNExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Frozen ResNet18 feature extractor.\n",
    "    Outputs 512-dimensional features from penultimate layer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        resnet = resnet18(weights=weights)\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.eval()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            features = self.features(x)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        return features\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Quantum Head (No Entanglement)\n",
    "# ============================================\n",
    "\n",
    "class QuantumHead(nn.Module):\n",
    "    \"\"\"\n",
    "    VQC with 8 qubits, 3 layers, NO entanglement → 10 classes.\n",
    "    Uses Lightning acceleration (GPU).\n",
    "    Maps 512 CNN features → 8 qubits.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=512, n_qubits=8, n_layers=3, num_classes=10, device_name=None):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Map 512 features → n_qubits\n",
    "        self.feature_select = nn.Linear(input_dim, n_qubits)\n",
    "\n",
    "        # Use specified device or default\n",
    "        if device_name is None:\n",
    "            device_name = QUANTUM_DEVICE\n",
    "        \n",
    "        # Quantum device\n",
    "        self.dev = qml.device(device_name, wires=n_qubits)\n",
    "\n",
    "        # Use adjoint differentiation for lightning (much faster)\n",
    "        diff_method = \"adjoint\" if \"lightning\" in device_name else \"parameter-shift\"\n",
    "\n",
    "        @qml.qnode(self.dev, interface=\"torch\", diff_method=diff_method)\n",
    "        def quantum_circuit(inputs, weights):\n",
    "            \"\"\"\n",
    "            Single-sample circuit WITHOUT entanglement.\n",
    "            inputs: (n_qubits,)\n",
    "            weights: (n_layers, n_qubits, 2)\n",
    "            \"\"\"\n",
    "            for layer in range(n_layers):\n",
    "                # Data re-uploading\n",
    "                for i in range(n_qubits):\n",
    "                    qml.RY(inputs[i], wires=i)\n",
    "\n",
    "                # Trainable rotations\n",
    "                for i in range(n_qubits):\n",
    "                    qml.RY(weights[layer, i, 0], wires=i)\n",
    "                    qml.RZ(weights[layer, i, 1], wires=i)\n",
    "\n",
    "                # NO ENTANGLEMENT\n",
    "\n",
    "            # Measure more observables for richer output (12 measurements)\n",
    "            measurements = []\n",
    "            # Single-qubit Z measurements\n",
    "            for i in range(n_qubits):\n",
    "                measurements.append(qml.expval(qml.PauliZ(i)))\n",
    "            # Two-qubit ZZ measurements (pairs)\n",
    "            for i in range(0, n_qubits-1, 2):\n",
    "                measurements.append(qml.expval(qml.PauliZ(i) @ qml.PauliZ(i+1)))\n",
    "            \n",
    "            return measurements\n",
    "\n",
    "        self.quantum_circuit = quantum_circuit\n",
    "\n",
    "        weight_shape = (n_layers, n_qubits, 2)\n",
    "        self.q_weights = nn.Parameter(torch.randn(weight_shape) * 0.1)\n",
    "        \n",
    "        # Output layer: 12 measurements → 10 classes\n",
    "        n_measurements = n_qubits + (n_qubits // 2)\n",
    "        self.fc_out = nn.Linear(n_measurements, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Process samples with progress tracking.\n",
    "        x: (batch, 512) CNN features\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.tanh(self.feature_select(x))\n",
    "\n",
    "        # Process in chunks for memory management\n",
    "        chunk_size = 32\n",
    "        quantum_outputs = []\n",
    "\n",
    "        for start_idx in range(0, batch_size, chunk_size):\n",
    "            end_idx = min(start_idx + chunk_size, batch_size)\n",
    "            chunk = x[start_idx:end_idx]\n",
    "\n",
    "            chunk_outputs = []\n",
    "            for i in range(chunk.size(0)):\n",
    "                q_raw = self.quantum_circuit(chunk[i], self.q_weights)\n",
    "                if isinstance(q_raw, (list, tuple)):\n",
    "                    q_out = torch.stack(q_raw)\n",
    "                else:\n",
    "                    q_out = q_raw\n",
    "                chunk_outputs.append(q_out)\n",
    "\n",
    "            quantum_outputs.extend(chunk_outputs)\n",
    "\n",
    "        # Convert to tensor (cast to float32)\n",
    "        quantum_outputs = torch.stack(quantum_outputs).float()\n",
    "        quantum_outputs = quantum_outputs.to(self.fc_out.weight.dtype)\n",
    "\n",
    "        output = self.fc_out(quantum_outputs)\n",
    "        return output\n",
    "\n",
    "\n",
    "class QuantumNetCNN(nn.Module):\n",
    "    \"\"\"Complete Quantum network: Frozen CNN + QuantumHead (no ent)\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_extractor = FrozenCNNExtractor()\n",
    "        self.head = QuantumHead(input_dim=512, n_qubits=8, n_layers=3, num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN on GPU\n",
    "        features = self.cnn_extractor(x)\n",
    "        # Move to CPU for quantum processing\n",
    "        features_cpu = features.cpu()\n",
    "        return self.head(features_cpu)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Training and Evaluation\n",
    "# ============================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device, show_progress=True):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        # Move images to GPU for CNN\n",
    "        x = x.to(device)\n",
    "        # Keep labels on CPU\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total_samples += x.size(0)\n",
    "\n",
    "        if show_progress and batch_idx % 20 == 0:\n",
    "            print(f\"    Batch {batch_idx}/{len(loader)}, samples: {total_samples}\", end=\"\\r\")\n",
    "\n",
    "    if show_progress:\n",
    "        print()\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            # Move images to GPU for CNN\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "def train_with_early_stopping(model, train_loader, test_loader, optimizer,\n",
    "                              device, max_epochs=200, patience=10, name=\"Model\"):\n",
    "    best_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    start = time.time()\n",
    "    last_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        print(f\"  [{name}] Epoch {epoch}/{max_epochs}\")\n",
    "        loss = train_one_epoch(model, train_loader, optimizer, device, show_progress=True)\n",
    "        acc = evaluate(model, test_loader, device)\n",
    "        last_acc = acc\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"  [{name}] Epoch {epoch:2d} | loss={loss:.4f} \"\n",
    "              f\"| test_acc={acc:.4f} | time={elapsed:.1f}s\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"  [{name}] Early stop at epoch {epoch} \"\n",
    "                  f\"(no improvement for {patience} epochs)\")\n",
    "            break\n",
    "\n",
    "    total_time = time.time() - start\n",
    "    return {\n",
    "        \"best_acc\": best_acc,\n",
    "        \"final_acc\": last_acc,\n",
    "        \"time\": total_time,\n",
    "        \"epochs\": epoch,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Data utilities\n",
    "# ============================================\n",
    "\n",
    "def stratified_sample_from_targets(dataset, n_samples_per_class, seed=42):\n",
    "    \"\"\"\n",
    "    Create a stratified sample with n_samples_per_class from each class.\n",
    "    Uses dataset.targets directly - NO image loading during sampling.\n",
    "    \"\"\"\n",
    "    if hasattr(dataset, 'targets'):\n",
    "        targets = np.array(dataset.targets)\n",
    "    else:\n",
    "        targets = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "    \n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    sampled_indices = []\n",
    "    for c in range(10):\n",
    "        idx_c = np.where(targets == c)[0]\n",
    "        k = min(n_samples_per_class, len(idx_c))\n",
    "        selected = rng.choice(idx_c, size=k, replace=False).tolist()\n",
    "        sampled_indices.extend(selected)\n",
    "    \n",
    "    rng.shuffle(sampled_indices)\n",
    "    return sampled_indices\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Main\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BLOCK 3: Quantum (NO Entanglement) Training with Frozen CNN (CIFAR-10)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nConfiguration:\")\n",
    "    print(\"  • Dataset: CIFAR-10 (32×32 RGB)\")\n",
    "    print(\"  • CNN Backbone: ResNet18 (FROZEN)\")\n",
    "    print(\"  • Batch size: 32\")\n",
    "    print(\"  • Patience: 10\")\n",
    "    print(\"  • Max epochs: 200\")\n",
    "    print(\"  • Seeds: [42, 123, 456]\")\n",
    "    print(\"  • Architecture: CNN(frozen) → 512 → 8 qubits (3 layers, NO ent) → 10\")\n",
    "    print(f\"  • Quantum device: {QUANTUM_DEVICE}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Load frozen CNN from Block 1\n",
    "    print(\"\\nLoading frozen CNN from Block 1...\")\n",
    "    try:\n",
    "        realnet_data = torch.load(\"realnet_cnn_cifar10_results.pt\", weights_only=False)\n",
    "        frozen_cnn_state = realnet_data[\"frozen_cnn_state\"]\n",
    "        print(\"✓ Loaded frozen CNN state from realnet_cnn_cifar10_results.pt\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"✗ ERROR: realnet_cnn_cifar10_results.pt not found!\")\n",
    "        print(\"  Run Block 1 first to train RealNet and save frozen CNN.\")\n",
    "        return\n",
    "\n",
    "    # Create frozen CNN\n",
    "    shared_cnn = FrozenCNNExtractor().to(device)\n",
    "    shared_cnn.load_state_dict(frozen_cnn_state)\n",
    "    for p in shared_cnn.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    cnn_params = sum(p.numel() for p in shared_cnn.parameters())\n",
    "    print(f\"  CNN frozen with {cnn_params:,} params\")\n",
    "\n",
    "    # Load data - ImageNet normalization\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    full_train_ds = datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                     download=True, transform=transform)\n",
    "    full_test_ds = datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                    download=True, transform=transform)\n",
    "\n",
    "    # Create stratified samples\n",
    "    print(\"\\nCreating stratified samples...\")\n",
    "    t0 = time.time()\n",
    "    train_indices = stratified_sample_from_targets(full_train_ds, n_samples_per_class=1500, seed=42)\n",
    "    test_indices = stratified_sample_from_targets(full_test_ds, n_samples_per_class=300, seed=42)\n",
    "    print(f\"  Sampling took {time.time()-t0:.2f}s\")\n",
    "    \n",
    "    train_ds = Subset(full_train_ds, train_indices)\n",
    "    test_ds = Subset(full_test_ds, test_indices)\n",
    "    \n",
    "    print(f\"  Train samples: {len(train_ds)} (stratified, 1500 per class)\")\n",
    "    print(f\"  Test samples:  {len(test_ds)} (stratified, 300 per class)\")\n",
    "\n",
    "    # Smaller batches for quantum\n",
    "    train_loader = DataLoader(train_ds, batch_size=32,\n",
    "                              shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_ds, batch_size=64,\n",
    "                             shuffle=False, num_workers=0)\n",
    "\n",
    "    seeds = [42, 123, 456]\n",
    "    all_results = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\"SEED {seed}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        set_all_seeds(seed)\n",
    "\n",
    "        print(f\"\\n  Training QuantumNet-CNN (NO entanglement, seed={seed})...\")\n",
    "        quantum_model = QuantumNetCNN()\n",
    "        quantum_model.cnn_extractor = shared_cnn  # Use frozen CNN\n",
    "        \n",
    "        # Only optimize quantum head parameters\n",
    "        quantum_opt = torch.optim.Adam(quantum_model.head.parameters(), lr=1e-3)\n",
    "        \n",
    "        result = train_with_early_stopping(\n",
    "            quantum_model, train_loader, test_loader, quantum_opt, device,\n",
    "            max_epochs=200, patience=10, name=\"QuantumNoEnt-CNN\"\n",
    "        )\n",
    "        \n",
    "        trainable_params = sum(p.numel() for p in quantum_model.head.parameters())\n",
    "        total_params = sum(p.numel() for p in quantum_model.parameters())\n",
    "        \n",
    "        result[\"trainable_params\"] = trainable_params\n",
    "        result[\"total_params\"] = total_params\n",
    "        result[\"seed\"] = seed\n",
    "        \n",
    "        all_results.append(result)\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"QUANTUM (NO ENTANGLEMENT) + CNN SUMMARY (CIFAR-10)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    accs = [r[\"best_acc\"] for r in all_results]\n",
    "    times = [r[\"time\"] for r in all_results]\n",
    "    epochs = [r[\"epochs\"] for r in all_results]\n",
    "    trainable = all_results[0][\"trainable_params\"]\n",
    "    total = all_results[0][\"total_params\"]\n",
    "    \n",
    "    print(f\"\\nAccuracy:          {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "    print(f\"Time:              {np.mean(times):.1f}s ± {np.std(times):.1f}s\")\n",
    "    print(f\"Epochs:            {np.mean(epochs):.1f} ± {np.std(epochs):.1f}\")\n",
    "    print(f\"Trainable params:  {trainable:,}\")\n",
    "    print(f\"Total params:      {total:,}\")\n",
    "    print(f\"Frozen params:     {total - trainable:,}\")\n",
    "    \n",
    "    print(\"\\nPer-seed results:\")\n",
    "    for r in all_results:\n",
    "        print(f\"  Seed {r['seed']}: acc={r['best_acc']:.4f}, \"\n",
    "              f\"time={r['time']:.1f}s, epochs={r['epochs']}\")\n",
    "\n",
    "    # Save results\n",
    "    save_dict = {\n",
    "        \"results\": all_results,\n",
    "        \"summary\": {\n",
    "            \"mean_acc\": np.mean(accs),\n",
    "            \"std_acc\": np.std(accs),\n",
    "            \"mean_time\": np.mean(times),\n",
    "            \"trainable_params\": trainable,\n",
    "            \"total_params\": total\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    torch.save(save_dict, \"quantum_noent_cnn_cifar10_results.pt\")\n",
    "    print(f\"\\n✓ Saved results to: quantum_noent_cnn_cifar10_results.pt\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb301b4-7718-4261-bedc-4cc6098b59a6",
   "metadata": {},
   "source": [
    "# Quantum Ent CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d162d344-4a43-4960-9e82-beb90d107e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using lightning.gpu device\n",
      "Using PyTorch device: cuda\n",
      "======================================================================\n",
      "BLOCK 4: Quantum (WITH Entanglement) Training with Frozen CNN (CIFAR-10)\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  • Dataset: CIFAR-10 (32×32 RGB)\n",
      "  • CNN Backbone: ResNet18 (FROZEN)\n",
      "  • Batch size: 32\n",
      "  • Patience: 10\n",
      "  • Max epochs: 200\n",
      "  • Seeds: [42, 123, 456]\n",
      "  • Architecture: CNN(frozen) → 512 → 8 qubits (3 layers, WITH ent) → 10\n",
      "  • Quantum device: lightning.gpu\n",
      "======================================================================\n",
      "\n",
      "Loading frozen CNN from Block 1...\n",
      "✓ Loaded frozen CNN state from realnet_cnn_cifar10_results.pt\n",
      "  CNN frozen with 11,176,512 params\n",
      "\n",
      "Creating stratified samples...\n",
      "  Sampling took 0.00s\n",
      "  Train samples: 15000 (stratified, 1500 per class)\n",
      "  Test samples:  3000 (stratified, 300 per class)\n",
      "\n",
      "======================================================================\n",
      "SEED 42\n",
      "======================================================================\n",
      "\n",
      "  Training QuantumNet-CNN (WITH entanglement, seed=42)...\n",
      "  [QuantumEnt-CNN] Epoch 1/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  1 | loss=2.2425 | test_acc=0.2273 | time=1439.6s\n",
      "  [QuantumEnt-CNN] Epoch 2/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  2 | loss=2.0469 | test_acc=0.2607 | time=2904.3s\n",
      "  [QuantumEnt-CNN] Epoch 3/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  3 | loss=1.9585 | test_acc=0.2460 | time=4449.3s\n",
      "  [QuantumEnt-CNN] Epoch 4/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  4 | loss=1.9386 | test_acc=0.2593 | time=5997.4s\n",
      "  [QuantumEnt-CNN] Epoch 5/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  5 | loss=1.9145 | test_acc=0.2733 | time=7603.4s\n",
      "  [QuantumEnt-CNN] Epoch 6/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  6 | loss=1.9044 | test_acc=0.2890 | time=9193.4s\n",
      "  [QuantumEnt-CNN] Epoch 7/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  7 | loss=1.8965 | test_acc=0.2930 | time=10745.7s\n",
      "  [QuantumEnt-CNN] Epoch 8/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  8 | loss=1.8839 | test_acc=0.3060 | time=12269.7s\n",
      "  [QuantumEnt-CNN] Epoch 9/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  9 | loss=1.8733 | test_acc=0.2917 | time=13789.1s\n",
      "  [QuantumEnt-CNN] Epoch 10/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 10 | loss=1.8716 | test_acc=0.3110 | time=15288.5s\n",
      "  [QuantumEnt-CNN] Epoch 11/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 11 | loss=1.8631 | test_acc=0.3037 | time=16753.9s\n",
      "  [QuantumEnt-CNN] Epoch 12/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 12 | loss=1.8486 | test_acc=0.2950 | time=18246.7s\n",
      "  [QuantumEnt-CNN] Epoch 13/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 13 | loss=1.8556 | test_acc=0.3057 | time=19739.9s\n",
      "  [QuantumEnt-CNN] Epoch 14/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 14 | loss=1.8488 | test_acc=0.3203 | time=21244.9s\n",
      "  [QuantumEnt-CNN] Epoch 15/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 15 | loss=1.8526 | test_acc=0.3207 | time=22766.6s\n",
      "  [QuantumEnt-CNN] Epoch 16/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 16 | loss=1.8536 | test_acc=0.3223 | time=24270.7s\n",
      "  [QuantumEnt-CNN] Epoch 17/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 17 | loss=1.8469 | test_acc=0.3207 | time=25814.3s\n",
      "  [QuantumEnt-CNN] Epoch 18/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 18 | loss=1.8427 | test_acc=0.3080 | time=27332.2s\n",
      "  [QuantumEnt-CNN] Epoch 19/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 19 | loss=1.8341 | test_acc=0.3190 | time=28804.3s\n",
      "  [QuantumEnt-CNN] Epoch 20/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 20 | loss=1.8364 | test_acc=0.3200 | time=30307.0s\n",
      "  [QuantumEnt-CNN] Epoch 21/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 21 | loss=1.8341 | test_acc=0.3273 | time=31822.6s\n",
      "  [QuantumEnt-CNN] Epoch 22/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 22 | loss=1.8372 | test_acc=0.3170 | time=33316.6s\n",
      "  [QuantumEnt-CNN] Epoch 23/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 23 | loss=1.8275 | test_acc=0.3070 | time=34778.9s\n",
      "  [QuantumEnt-CNN] Epoch 24/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 24 | loss=1.8313 | test_acc=0.3217 | time=36309.1s\n",
      "  [QuantumEnt-CNN] Epoch 25/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 25 | loss=1.8230 | test_acc=0.3257 | time=37781.0s\n",
      "  [QuantumEnt-CNN] Epoch 26/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 26 | loss=1.8242 | test_acc=0.3293 | time=39253.4s\n",
      "  [QuantumEnt-CNN] Epoch 27/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 27 | loss=1.8241 | test_acc=0.3300 | time=40745.8s\n",
      "  [QuantumEnt-CNN] Epoch 28/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 28 | loss=1.8157 | test_acc=0.3293 | time=42241.5s\n",
      "  [QuantumEnt-CNN] Epoch 29/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 29 | loss=1.8200 | test_acc=0.3320 | time=43729.4s\n",
      "  [QuantumEnt-CNN] Epoch 30/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 30 | loss=1.8286 | test_acc=0.3217 | time=45244.1s\n",
      "  [QuantumEnt-CNN] Epoch 31/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 31 | loss=1.8261 | test_acc=0.3343 | time=46734.4s\n",
      "  [QuantumEnt-CNN] Epoch 32/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 32 | loss=1.8229 | test_acc=0.3407 | time=48224.7s\n",
      "  [QuantumEnt-CNN] Epoch 33/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 33 | loss=1.8261 | test_acc=0.3317 | time=49699.9s\n",
      "  [QuantumEnt-CNN] Epoch 34/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 34 | loss=1.8167 | test_acc=0.3323 | time=51165.7s\n",
      "  [QuantumEnt-CNN] Epoch 35/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 35 | loss=1.8198 | test_acc=0.3330 | time=52627.2s\n",
      "  [QuantumEnt-CNN] Epoch 36/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 36 | loss=1.8241 | test_acc=0.3373 | time=54113.7s\n",
      "  [QuantumEnt-CNN] Epoch 37/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 37 | loss=1.8202 | test_acc=0.3223 | time=55592.4s\n",
      "  [QuantumEnt-CNN] Epoch 38/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 38 | loss=1.8238 | test_acc=0.3440 | time=57075.3s\n",
      "  [QuantumEnt-CNN] Epoch 39/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 39 | loss=1.8186 | test_acc=0.3367 | time=58534.1s\n",
      "  [QuantumEnt-CNN] Epoch 40/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 40 | loss=1.8209 | test_acc=0.3337 | time=60033.7s\n",
      "  [QuantumEnt-CNN] Epoch 41/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 41 | loss=1.8097 | test_acc=0.3253 | time=61553.4s\n",
      "  [QuantumEnt-CNN] Epoch 42/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 42 | loss=1.8131 | test_acc=0.3360 | time=63116.7s\n",
      "  [QuantumEnt-CNN] Epoch 43/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 43 | loss=1.8137 | test_acc=0.3390 | time=64725.2s\n",
      "  [QuantumEnt-CNN] Epoch 44/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 44 | loss=1.8102 | test_acc=0.3373 | time=66171.5s\n",
      "  [QuantumEnt-CNN] Epoch 45/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 45 | loss=1.8114 | test_acc=0.3280 | time=67618.9s\n",
      "  [QuantumEnt-CNN] Epoch 46/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 46 | loss=1.8178 | test_acc=0.3390 | time=69073.5s\n",
      "  [QuantumEnt-CNN] Epoch 47/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 47 | loss=1.8175 | test_acc=0.3290 | time=70533.2s\n",
      "  [QuantumEnt-CNN] Epoch 48/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 48 | loss=1.8231 | test_acc=0.3430 | time=72053.4s\n",
      "  [QuantumEnt-CNN] Early stop at epoch 48 (no improvement for 10 epochs)\n",
      "\n",
      "======================================================================\n",
      "SEED 123\n",
      "======================================================================\n",
      "\n",
      "  Training QuantumNet-CNN (WITH entanglement, seed=123)...\n",
      "  [QuantumEnt-CNN] Epoch 1/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  1 | loss=2.2268 | test_acc=0.2123 | time=5203.9s\n",
      "  [QuantumEnt-CNN] Epoch 2/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  2 | loss=2.0567 | test_acc=0.2240 | time=8469.6s\n",
      "  [QuantumEnt-CNN] Epoch 3/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  3 | loss=2.0163 | test_acc=0.2137 | time=9923.2s\n",
      "  [QuantumEnt-CNN] Epoch 4/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  4 | loss=2.0015 | test_acc=0.2250 | time=11394.3s\n",
      "  [QuantumEnt-CNN] Epoch 5/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  5 | loss=1.9874 | test_acc=0.2423 | time=12922.6s\n",
      "  [QuantumEnt-CNN] Epoch 6/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  6 | loss=1.9801 | test_acc=0.2363 | time=14402.1s\n",
      "  [QuantumEnt-CNN] Epoch 7/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  7 | loss=1.9833 | test_acc=0.2403 | time=15876.5s\n",
      "  [QuantumEnt-CNN] Epoch 8/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  8 | loss=1.9838 | test_acc=0.2477 | time=17359.1s\n",
      "  [QuantumEnt-CNN] Epoch 9/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  9 | loss=1.9752 | test_acc=0.2390 | time=18829.6s\n",
      "  [QuantumEnt-CNN] Epoch 10/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 10 | loss=1.9714 | test_acc=0.2443 | time=20327.2s\n",
      "  [QuantumEnt-CNN] Epoch 11/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 11 | loss=1.9680 | test_acc=0.2377 | time=21812.8s\n",
      "  [QuantumEnt-CNN] Epoch 12/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 12 | loss=1.9708 | test_acc=0.2463 | time=23285.5s\n",
      "  [QuantumEnt-CNN] Epoch 13/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 13 | loss=1.9726 | test_acc=0.2480 | time=24751.3s\n",
      "  [QuantumEnt-CNN] Epoch 14/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 14 | loss=1.9672 | test_acc=0.2437 | time=26289.7s\n",
      "  [QuantumEnt-CNN] Epoch 15/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 15 | loss=1.9700 | test_acc=0.2483 | time=27834.0s\n",
      "  [QuantumEnt-CNN] Epoch 16/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 16 | loss=1.9541 | test_acc=0.2513 | time=29346.9s\n",
      "  [QuantumEnt-CNN] Epoch 17/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 17 | loss=1.9579 | test_acc=0.2480 | time=30850.8s\n",
      "  [QuantumEnt-CNN] Epoch 18/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 18 | loss=1.9551 | test_acc=0.2503 | time=32331.4s\n",
      "  [QuantumEnt-CNN] Epoch 19/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 19 | loss=1.9549 | test_acc=0.2587 | time=33827.9s\n",
      "  [QuantumEnt-CNN] Epoch 20/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 20 | loss=1.9470 | test_acc=0.2553 | time=35327.7s\n",
      "  [QuantumEnt-CNN] Epoch 21/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 21 | loss=1.9322 | test_acc=0.2720 | time=36836.4s\n",
      "  [QuantumEnt-CNN] Epoch 22/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 22 | loss=1.9188 | test_acc=0.2683 | time=38356.3s\n",
      "  [QuantumEnt-CNN] Epoch 23/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 23 | loss=1.9072 | test_acc=0.2653 | time=39913.9s\n",
      "  [QuantumEnt-CNN] Epoch 24/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 24 | loss=1.9076 | test_acc=0.2690 | time=41424.1s\n",
      "  [QuantumEnt-CNN] Epoch 25/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 25 | loss=1.8993 | test_acc=0.2730 | time=42933.0s\n",
      "  [QuantumEnt-CNN] Epoch 26/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 26 | loss=1.8978 | test_acc=0.2753 | time=44445.8s\n",
      "  [QuantumEnt-CNN] Epoch 27/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 27 | loss=1.8967 | test_acc=0.2700 | time=45983.9s\n",
      "  [QuantumEnt-CNN] Epoch 28/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 28 | loss=1.8925 | test_acc=0.2720 | time=47510.6s\n",
      "  [QuantumEnt-CNN] Epoch 29/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 29 | loss=1.8915 | test_acc=0.2753 | time=49029.4s\n",
      "  [QuantumEnt-CNN] Epoch 30/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 30 | loss=1.9069 | test_acc=0.2700 | time=50590.4s\n",
      "  [QuantumEnt-CNN] Epoch 31/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 31 | loss=1.8898 | test_acc=0.2797 | time=52090.2s\n",
      "  [QuantumEnt-CNN] Epoch 32/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 32 | loss=1.8861 | test_acc=0.2753 | time=53585.7s\n",
      "  [QuantumEnt-CNN] Epoch 33/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 33 | loss=1.8854 | test_acc=0.2697 | time=55098.4s\n",
      "  [QuantumEnt-CNN] Epoch 34/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 34 | loss=1.8912 | test_acc=0.2700 | time=56607.3s\n",
      "  [QuantumEnt-CNN] Epoch 35/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 35 | loss=1.8965 | test_acc=0.2713 | time=58135.7s\n",
      "  [QuantumEnt-CNN] Epoch 36/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 36 | loss=1.8841 | test_acc=0.2717 | time=59633.0s\n",
      "  [QuantumEnt-CNN] Epoch 37/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 37 | loss=1.8872 | test_acc=0.2793 | time=61123.4s\n",
      "  [QuantumEnt-CNN] Epoch 38/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 38 | loss=1.8891 | test_acc=0.2620 | time=62607.6s\n",
      "  [QuantumEnt-CNN] Epoch 39/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 39 | loss=1.8934 | test_acc=0.2657 | time=64102.6s\n",
      "  [QuantumEnt-CNN] Epoch 40/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 40 | loss=1.8907 | test_acc=0.2663 | time=65602.3s\n",
      "  [QuantumEnt-CNN] Epoch 41/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 41 | loss=1.8830 | test_acc=0.2703 | time=67116.3s\n",
      "  [QuantumEnt-CNN] Early stop at epoch 41 (no improvement for 10 epochs)\n",
      "\n",
      "======================================================================\n",
      "SEED 456\n",
      "======================================================================\n",
      "\n",
      "  Training QuantumNet-CNN (WITH entanglement, seed=456)...\n",
      "  [QuantumEnt-CNN] Epoch 1/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  1 | loss=2.1616 | test_acc=0.2550 | time=1557.0s\n",
      "  [QuantumEnt-CNN] Epoch 2/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  2 | loss=1.9942 | test_acc=0.2933 | time=3079.9s\n",
      "  [QuantumEnt-CNN] Epoch 3/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  3 | loss=1.9537 | test_acc=0.2903 | time=4561.3s\n",
      "  [QuantumEnt-CNN] Epoch 4/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  4 | loss=1.9110 | test_acc=0.2940 | time=6037.5s\n",
      "  [QuantumEnt-CNN] Epoch 5/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  5 | loss=1.8806 | test_acc=0.3233 | time=7515.2s\n",
      "  [QuantumEnt-CNN] Epoch 6/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  6 | loss=1.8762 | test_acc=0.3160 | time=9017.1s\n",
      "  [QuantumEnt-CNN] Epoch 7/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  7 | loss=1.8599 | test_acc=0.3233 | time=10525.1s\n",
      "  [QuantumEnt-CNN] Epoch 8/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  8 | loss=1.8580 | test_acc=0.3280 | time=12030.3s\n",
      "  [QuantumEnt-CNN] Epoch 9/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch  9 | loss=1.8537 | test_acc=0.3227 | time=13530.1s\n",
      "  [QuantumEnt-CNN] Epoch 10/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 10 | loss=1.8398 | test_acc=0.3313 | time=15014.0s\n",
      "  [QuantumEnt-CNN] Epoch 11/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 11 | loss=1.8374 | test_acc=0.3193 | time=16492.4s\n",
      "  [QuantumEnt-CNN] Epoch 12/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 12 | loss=1.8304 | test_acc=0.3437 | time=17983.6s\n",
      "  [QuantumEnt-CNN] Epoch 13/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 13 | loss=1.8330 | test_acc=0.3287 | time=19486.9s\n",
      "  [QuantumEnt-CNN] Epoch 14/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 14 | loss=1.8291 | test_acc=0.3397 | time=21004.0s\n",
      "  [QuantumEnt-CNN] Epoch 15/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 15 | loss=1.8157 | test_acc=0.3227 | time=22521.4s\n",
      "  [QuantumEnt-CNN] Epoch 16/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 16 | loss=1.8300 | test_acc=0.3333 | time=24025.5s\n",
      "  [QuantumEnt-CNN] Epoch 17/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 17 | loss=1.8313 | test_acc=0.3303 | time=25537.6s\n",
      "  [QuantumEnt-CNN] Epoch 18/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 18 | loss=1.8177 | test_acc=0.3350 | time=27061.8s\n",
      "  [QuantumEnt-CNN] Epoch 19/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 19 | loss=1.8251 | test_acc=0.3413 | time=28570.1s\n",
      "  [QuantumEnt-CNN] Epoch 20/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 20 | loss=1.8282 | test_acc=0.3313 | time=30106.1s\n",
      "  [QuantumEnt-CNN] Epoch 21/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 21 | loss=1.8204 | test_acc=0.3443 | time=31630.3s\n",
      "  [QuantumEnt-CNN] Epoch 22/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 22 | loss=1.8181 | test_acc=0.3377 | time=33181.6s\n",
      "  [QuantumEnt-CNN] Epoch 23/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 23 | loss=1.8134 | test_acc=0.3310 | time=34705.0s\n",
      "  [QuantumEnt-CNN] Epoch 24/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 24 | loss=1.8181 | test_acc=0.3440 | time=36228.2s\n",
      "  [QuantumEnt-CNN] Epoch 25/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 25 | loss=1.8108 | test_acc=0.3357 | time=37758.0s\n",
      "  [QuantumEnt-CNN] Epoch 26/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 26 | loss=1.8159 | test_acc=0.3330 | time=39292.5s\n",
      "  [QuantumEnt-CNN] Epoch 27/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 27 | loss=1.8046 | test_acc=0.3233 | time=40847.7s\n",
      "  [QuantumEnt-CNN] Epoch 28/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 28 | loss=1.8151 | test_acc=0.3367 | time=42373.7s\n",
      "  [QuantumEnt-CNN] Epoch 29/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 29 | loss=1.8142 | test_acc=0.3500 | time=43894.6s\n",
      "  [QuantumEnt-CNN] Epoch 30/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 30 | loss=1.8122 | test_acc=0.3347 | time=45418.5s\n",
      "  [QuantumEnt-CNN] Epoch 31/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 31 | loss=1.8038 | test_acc=0.3343 | time=46945.5s\n",
      "  [QuantumEnt-CNN] Epoch 32/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 32 | loss=1.8045 | test_acc=0.3370 | time=48470.1s\n",
      "  [QuantumEnt-CNN] Epoch 33/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 33 | loss=1.8091 | test_acc=0.3390 | time=49972.5s\n",
      "  [QuantumEnt-CNN] Epoch 34/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 34 | loss=1.8102 | test_acc=0.3467 | time=51464.6s\n",
      "  [QuantumEnt-CNN] Epoch 35/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 35 | loss=1.8038 | test_acc=0.3397 | time=53015.4s\n",
      "  [QuantumEnt-CNN] Epoch 36/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 36 | loss=1.8052 | test_acc=0.3453 | time=54568.0s\n",
      "  [QuantumEnt-CNN] Epoch 37/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 37 | loss=1.8089 | test_acc=0.3403 | time=56097.0s\n",
      "  [QuantumEnt-CNN] Epoch 38/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 38 | loss=1.8109 | test_acc=0.3357 | time=57645.5s\n",
      "  [QuantumEnt-CNN] Epoch 39/200\n",
      "    Batch 460/469, samples: 14752\n",
      "  [QuantumEnt-CNN] Epoch 39 | loss=1.8168 | test_acc=0.3457 | time=59173.2s\n",
      "  [QuantumEnt-CNN] Early stop at epoch 39 (no improvement for 10 epochs)\n",
      "\n",
      "======================================================================\n",
      "QUANTUM (WITH ENTANGLEMENT) + CNN SUMMARY (CIFAR-10)\n",
      "======================================================================\n",
      "\n",
      "Accuracy:          0.3246 ± 0.0318\n",
      "Time:              66114.3s ± 5305.9s\n",
      "Epochs:            42.7 ± 3.9\n",
      "Trainable params:  4,282\n",
      "Total params:      11,180,794\n",
      "Frozen params:     11,176,512\n",
      "\n",
      "Per-seed results:\n",
      "  Seed 42: acc=0.3440, time=72053.4s, epochs=48\n",
      "  Seed 123: acc=0.2797, time=67116.3s, epochs=41\n",
      "  Seed 456: acc=0.3500, time=59173.2s, epochs=39\n",
      "\n",
      "✓ Saved results to: quantum_ent_cnn_cifar10_results.pt\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Block 4: Quantum (WITH Entanglement) Training with Frozen CNN (CIFAR-10)\n",
    "=========================================================================\n",
    "Loads frozen CNN from Block 1 and trains quantum head WITH entanglement.\n",
    "Uses Lightning-GPU acceleration.\n",
    "\n",
    "Requirements:\n",
    "- realnet_cnn_cifar10_results.pt (from Block 1)\n",
    "- pennylane, pennylane-lightning-gpu\n",
    "\n",
    "Outputs:\n",
    "- quantum_ent_cnn_cifar10_results.pt: Contains quantum (with ent) results\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "try:\n",
    "    import pennylane as qml\n",
    "    QUANTUM_DEVICE = \"lightning.gpu\"\n",
    "    PENNYLANE_AVAILABLE = True\n",
    "    print(\"✓ Using lightning.gpu device\")\n",
    "except ImportError:\n",
    "    PENNYLANE_AVAILABLE = False\n",
    "    print(\"✗ PennyLane not installed\")\n",
    "    exit(1)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using PyTorch device: {device}\")\n",
    "\n",
    "# ============================================\n",
    "# Comprehensive seed setting for reproducibility\n",
    "# ============================================\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    \"\"\"Set seeds for all RNG sources for reproducibility\"\"\"\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    # Python\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # PyTorch deterministic mode\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # CuPy (if available)\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        cp.random.seed(seed)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # PennyLane (if available)\n",
    "    try:\n",
    "        import pennylane as qml\n",
    "        qml.numpy.random.seed(seed)\n",
    "    except (ImportError, AttributeError):\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Frozen CNN Feature Extractor (from Block 1)\n",
    "# ============================================\n",
    "\n",
    "class FrozenCNNExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Frozen ResNet18 feature extractor.\n",
    "    Outputs 512-dimensional features from penultimate layer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        resnet = resnet18(weights=weights)\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.eval()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            features = self.features(x)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        return features\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Quantum Head (WITH Entanglement)\n",
    "# ============================================\n",
    "\n",
    "class QuantumHead(nn.Module):\n",
    "    \"\"\"\n",
    "    VQC with 8 qubits, 3 layers, WITH entanglement → 10 classes.\n",
    "    Uses Lightning acceleration (GPU).\n",
    "    Maps 512 CNN features → 8 qubits.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=512, n_qubits=8, n_layers=3, num_classes=10, device_name=None):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Map 512 features → n_qubits\n",
    "        self.feature_select = nn.Linear(input_dim, n_qubits)\n",
    "\n",
    "        # Use specified device or default\n",
    "        if device_name is None:\n",
    "            device_name = QUANTUM_DEVICE\n",
    "        \n",
    "        # Quantum device\n",
    "        self.dev = qml.device(device_name, wires=n_qubits)\n",
    "\n",
    "        # Use adjoint differentiation for lightning (much faster)\n",
    "        diff_method = \"adjoint\" if \"lightning\" in device_name else \"parameter-shift\"\n",
    "\n",
    "        @qml.qnode(self.dev, interface=\"torch\", diff_method=diff_method)\n",
    "        def quantum_circuit(inputs, weights):\n",
    "            \"\"\"\n",
    "            Single-sample circuit WITH entanglement.\n",
    "            inputs: (n_qubits,)\n",
    "            weights: (n_layers, n_qubits, 2)\n",
    "            \"\"\"\n",
    "            for layer in range(n_layers):\n",
    "                # Data re-uploading\n",
    "                for i in range(n_qubits):\n",
    "                    qml.RY(inputs[i], wires=i)\n",
    "\n",
    "                # Trainable rotations\n",
    "                for i in range(n_qubits):\n",
    "                    qml.RY(weights[layer, i, 0], wires=i)\n",
    "                    qml.RZ(weights[layer, i, 1], wires=i)\n",
    "\n",
    "                # ENTANGLEMENT: CNOT ring\n",
    "                for i in range(n_qubits - 1):\n",
    "                    qml.CNOT(wires=[i, i + 1])\n",
    "                if n_qubits > 2:\n",
    "                    qml.CNOT(wires=[n_qubits - 1, 0])\n",
    "\n",
    "            # Measure more observables for richer output (12 measurements)\n",
    "            measurements = []\n",
    "            # Single-qubit Z measurements\n",
    "            for i in range(n_qubits):\n",
    "                measurements.append(qml.expval(qml.PauliZ(i)))\n",
    "            # Two-qubit ZZ measurements (pairs)\n",
    "            for i in range(0, n_qubits-1, 2):\n",
    "                measurements.append(qml.expval(qml.PauliZ(i) @ qml.PauliZ(i+1)))\n",
    "            \n",
    "            return measurements\n",
    "\n",
    "        self.quantum_circuit = quantum_circuit\n",
    "\n",
    "        weight_shape = (n_layers, n_qubits, 2)\n",
    "        self.q_weights = nn.Parameter(torch.randn(weight_shape) * 0.1)\n",
    "        \n",
    "        # Output layer: 12 measurements → 10 classes\n",
    "        n_measurements = n_qubits + (n_qubits // 2)\n",
    "        self.fc_out = nn.Linear(n_measurements, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Process samples with progress tracking.\n",
    "        x: (batch, 512) CNN features\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.tanh(self.feature_select(x))\n",
    "\n",
    "        # Process in chunks for memory management\n",
    "        chunk_size = 32\n",
    "        quantum_outputs = []\n",
    "\n",
    "        for start_idx in range(0, batch_size, chunk_size):\n",
    "            end_idx = min(start_idx + chunk_size, batch_size)\n",
    "            chunk = x[start_idx:end_idx]\n",
    "\n",
    "            chunk_outputs = []\n",
    "            for i in range(chunk.size(0)):\n",
    "                q_raw = self.quantum_circuit(chunk[i], self.q_weights)\n",
    "                if isinstance(q_raw, (list, tuple)):\n",
    "                    q_out = torch.stack(q_raw)\n",
    "                else:\n",
    "                    q_out = q_raw\n",
    "                chunk_outputs.append(q_out)\n",
    "\n",
    "            quantum_outputs.extend(chunk_outputs)\n",
    "\n",
    "        # Convert to tensor (cast to float32)\n",
    "        quantum_outputs = torch.stack(quantum_outputs).float()\n",
    "        quantum_outputs = quantum_outputs.to(self.fc_out.weight.dtype)\n",
    "\n",
    "        output = self.fc_out(quantum_outputs)\n",
    "        return output\n",
    "\n",
    "\n",
    "class QuantumNetCNN(nn.Module):\n",
    "    \"\"\"Complete Quantum network: Frozen CNN + QuantumHead (with ent)\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_extractor = FrozenCNNExtractor()\n",
    "        self.head = QuantumHead(input_dim=512, n_qubits=8, n_layers=3, num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # CNN on GPU\n",
    "        features = self.cnn_extractor(x)\n",
    "        # Move to CPU for quantum processing\n",
    "        features_cpu = features.cpu()\n",
    "        return self.head(features_cpu)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Training and Evaluation\n",
    "# ============================================\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device, show_progress=True):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(loader):\n",
    "        # Move images to GPU for CNN\n",
    "        x = x.to(device)\n",
    "        # Keep labels on CPU\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total_samples += x.size(0)\n",
    "\n",
    "        if show_progress and batch_idx % 20 == 0:\n",
    "            print(f\"    Batch {batch_idx}/{len(loader)}, samples: {total_samples}\", end=\"\\r\")\n",
    "\n",
    "    if show_progress:\n",
    "        print()\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            # Move images to GPU for CNN\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "def train_with_early_stopping(model, train_loader, test_loader, optimizer,\n",
    "                              device, max_epochs=200, patience=10, name=\"Model\"):\n",
    "    best_acc = 0.0\n",
    "    epochs_without_improvement = 0\n",
    "    start = time.time()\n",
    "    last_acc = 0.0\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        print(f\"  [{name}] Epoch {epoch}/{max_epochs}\")\n",
    "        loss = train_one_epoch(model, train_loader, optimizer, device, show_progress=True)\n",
    "        acc = evaluate(model, test_loader, device)\n",
    "        last_acc = acc\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"  [{name}] Epoch {epoch:2d} | loss={loss:.4f} \"\n",
    "              f\"| test_acc={acc:.4f} | time={elapsed:.1f}s\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"  [{name}] Early stop at epoch {epoch} \"\n",
    "                  f\"(no improvement for {patience} epochs)\")\n",
    "            break\n",
    "\n",
    "    total_time = time.time() - start\n",
    "    return {\n",
    "        \"best_acc\": best_acc,\n",
    "        \"final_acc\": last_acc,\n",
    "        \"time\": total_time,\n",
    "        \"epochs\": epoch,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Data utilities\n",
    "# ============================================\n",
    "\n",
    "def stratified_sample_from_targets(dataset, n_samples_per_class, seed=42):\n",
    "    \"\"\"\n",
    "    Create a stratified sample with n_samples_per_class from each class.\n",
    "    Uses dataset.targets directly - NO image loading during sampling.\n",
    "    \"\"\"\n",
    "    if hasattr(dataset, 'targets'):\n",
    "        targets = np.array(dataset.targets)\n",
    "    else:\n",
    "        targets = np.array([dataset[i][1] for i in range(len(dataset))])\n",
    "    \n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    sampled_indices = []\n",
    "    for c in range(10):\n",
    "        idx_c = np.where(targets == c)[0]\n",
    "        k = min(n_samples_per_class, len(idx_c))\n",
    "        selected = rng.choice(idx_c, size=k, replace=False).tolist()\n",
    "        sampled_indices.extend(selected)\n",
    "    \n",
    "    rng.shuffle(sampled_indices)\n",
    "    return sampled_indices\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Main\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"BLOCK 4: Quantum (WITH Entanglement) Training with Frozen CNN (CIFAR-10)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nConfiguration:\")\n",
    "    print(\"  • Dataset: CIFAR-10 (32×32 RGB)\")\n",
    "    print(\"  • CNN Backbone: ResNet18 (FROZEN)\")\n",
    "    print(\"  • Batch size: 32\")\n",
    "    print(\"  • Patience: 10\")\n",
    "    print(\"  • Max epochs: 200\")\n",
    "    print(\"  • Seeds: [42, 123, 456]\")\n",
    "    print(\"  • Architecture: CNN(frozen) → 512 → 8 qubits (3 layers, WITH ent) → 10\")\n",
    "    print(f\"  • Quantum device: {QUANTUM_DEVICE}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Load frozen CNN from Block 1\n",
    "    print(\"\\nLoading frozen CNN from Block 1...\")\n",
    "    try:\n",
    "        realnet_data = torch.load(\"realnet_cnn_cifar10_results.pt\", weights_only=False)\n",
    "        frozen_cnn_state = realnet_data[\"frozen_cnn_state\"]\n",
    "        print(\"✓ Loaded frozen CNN state from realnet_cnn_cifar10_results.pt\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"✗ ERROR: realnet_cnn_cifar10_results.pt not found!\")\n",
    "        print(\"  Run Block 1 first to train RealNet and save frozen CNN.\")\n",
    "        return\n",
    "\n",
    "    # Create frozen CNN\n",
    "    shared_cnn = FrozenCNNExtractor().to(device)\n",
    "    shared_cnn.load_state_dict(frozen_cnn_state)\n",
    "    for p in shared_cnn.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    cnn_params = sum(p.numel() for p in shared_cnn.parameters())\n",
    "    print(f\"  CNN frozen with {cnn_params:,} params\")\n",
    "\n",
    "    # Load data - ImageNet normalization\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    full_train_ds = datasets.CIFAR10(root=\"./data\", train=True,\n",
    "                                     download=True, transform=transform)\n",
    "    full_test_ds = datasets.CIFAR10(root=\"./data\", train=False,\n",
    "                                    download=True, transform=transform)\n",
    "\n",
    "    # Create stratified samples\n",
    "    print(\"\\nCreating stratified samples...\")\n",
    "    t0 = time.time()\n",
    "    train_indices = stratified_sample_from_targets(full_train_ds, n_samples_per_class=1500, seed=42)\n",
    "    test_indices = stratified_sample_from_targets(full_test_ds, n_samples_per_class=300, seed=42)\n",
    "    print(f\"  Sampling took {time.time()-t0:.2f}s\")\n",
    "    \n",
    "    train_ds = Subset(full_train_ds, train_indices)\n",
    "    test_ds = Subset(full_test_ds, test_indices)\n",
    "    \n",
    "    print(f\"  Train samples: {len(train_ds)} (stratified, 1500 per class)\")\n",
    "    print(f\"  Test samples:  {len(test_ds)} (stratified, 300 per class)\")\n",
    "\n",
    "    # Smaller batches for quantum\n",
    "    train_loader = DataLoader(train_ds, batch_size=32,\n",
    "                              shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_ds, batch_size=64,\n",
    "                             shuffle=False, num_workers=0)\n",
    "\n",
    "    seeds = [42, 123, 456]\n",
    "    all_results = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(f\"\\n{'=' * 70}\")\n",
    "        print(f\"SEED {seed}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        set_all_seeds(seed)\n",
    "\n",
    "        print(f\"\\n  Training QuantumNet-CNN (WITH entanglement, seed={seed})...\")\n",
    "        quantum_model = QuantumNetCNN()\n",
    "        quantum_model.cnn_extractor = shared_cnn  # Use frozen CNN\n",
    "        \n",
    "        # Only optimize quantum head parameters\n",
    "        quantum_opt = torch.optim.Adam(quantum_model.head.parameters(), lr=1e-3)\n",
    "        \n",
    "        result = train_with_early_stopping(\n",
    "            quantum_model, train_loader, test_loader, quantum_opt, device,\n",
    "            max_epochs=200, patience=10, name=\"QuantumEnt-CNN\"\n",
    "        )\n",
    "        \n",
    "        trainable_params = sum(p.numel() for p in quantum_model.head.parameters())\n",
    "        total_params = sum(p.numel() for p in quantum_model.parameters())\n",
    "        \n",
    "        result[\"trainable_params\"] = trainable_params\n",
    "        result[\"total_params\"] = total_params\n",
    "        result[\"seed\"] = seed\n",
    "        \n",
    "        all_results.append(result)\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"QUANTUM (WITH ENTANGLEMENT) + CNN SUMMARY (CIFAR-10)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    accs = [r[\"best_acc\"] for r in all_results]\n",
    "    times = [r[\"time\"] for r in all_results]\n",
    "    epochs = [r[\"epochs\"] for r in all_results]\n",
    "    trainable = all_results[0][\"trainable_params\"]\n",
    "    total = all_results[0][\"total_params\"]\n",
    "    \n",
    "    print(f\"\\nAccuracy:          {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
    "    print(f\"Time:              {np.mean(times):.1f}s ± {np.std(times):.1f}s\")\n",
    "    print(f\"Epochs:            {np.mean(epochs):.1f} ± {np.std(epochs):.1f}\")\n",
    "    print(f\"Trainable params:  {trainable:,}\")\n",
    "    print(f\"Total params:      {total:,}\")\n",
    "    print(f\"Frozen params:     {total - trainable:,}\")\n",
    "    \n",
    "    print(\"\\nPer-seed results:\")\n",
    "    for r in all_results:\n",
    "        print(f\"  Seed {r['seed']}: acc={r['best_acc']:.4f}, \"\n",
    "              f\"time={r['time']:.1f}s, epochs={r['epochs']}\")\n",
    "\n",
    "    # Save results\n",
    "    save_dict = {\n",
    "        \"results\": all_results,\n",
    "        \"summary\": {\n",
    "            \"mean_acc\": np.mean(accs),\n",
    "            \"std_acc\": np.std(accs),\n",
    "            \"mean_time\": np.mean(times),\n",
    "            \"trainable_params\": trainable,\n",
    "            \"total_params\": total\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    torch.save(save_dict, \"quantum_ent_cnn_cifar10_results.pt\")\n",
    "    print(f\"\\n✓ Saved results to: quantum_ent_cnn_cifar10_results.pt\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9725ba5-dfa8-490d-9986-b5825f356f8f",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e94e066b-9f02-445b-9c72-eef190e56b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "BLOCK 5: AGGREGATE RESULTS AND COMPARATIVE ANALYSIS (CIFAR-10 + CNN)\n",
      "===============================================================================================\n",
      "✓ Loaded RealNet-CNN (CIFAR-10) results\n",
      "✓ Loaded QuatNet-CNN (CIFAR-10) results\n",
      "✓ Loaded Quantum-NoEnt-CNN (CIFAR-10) results\n",
      "✓ Loaded Quantum-Ent-CNN (CIFAR-10) results\n",
      "\n",
      "===============================================================================================\n",
      "AGGREGATED RESULTS (CIFAR-10 + CNN) (mean ± std over 3 seeds)\n",
      "===============================================================================================\n",
      "Model           Accuracy             Time (s)             Epochs          Trainable Params    \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Real            0.4713 ± 0.0070      14.2 ± 2.5           22.3 ± 4.0      66,954              \n",
      "Quat            0.4521 ± 0.0038      36.1 ± 0.2           40.0 ± 0.0      17,832              \n",
      "QNoEnt          0.4171 ± 0.0094      64739.2 ± 13399.7    48.7 ± 10.9     4,282               \n",
      "QEnt            0.3246 ± 0.0318      66114.3 ± 5305.9     42.7 ± 3.9      4,282               \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Frozen CNN      (shared)             -                    -               ~11M (ResNet18)     \n",
      "===============================================================================================\n",
      "\n",
      "======================================================================\n",
      "PER-SEED RESULTS (CIFAR-10 + CNN)\n",
      "======================================================================\n",
      "\n",
      "Seed 42:\n",
      "Model           Accuracy     Time (s)     Epochs    \n",
      "--------------------------------------------------\n",
      "Real            0.4683       17.7         28        \n",
      "Quat            0.4523       35.8         40        \n",
      "QNoEnt          0.4303       54249.7      40        \n",
      "QEnt            0.3440       72053.4      48        \n",
      "\n",
      "Seed 123:\n",
      "Model           Accuracy     Time (s)     Epochs    \n",
      "--------------------------------------------------\n",
      "Real            0.4810       12.3         20        \n",
      "Quat            0.4473       36.2         40        \n",
      "QNoEnt          0.4090       56316.3      42        \n",
      "QEnt            0.2797       67116.3      41        \n",
      "\n",
      "Seed 456:\n",
      "Model           Accuracy     Time (s)     Epochs    \n",
      "--------------------------------------------------\n",
      "Real            0.4647       12.6         19        \n",
      "Quat            0.4567       36.2         40        \n",
      "QNoEnt          0.4120       83651.7      64        \n",
      "QEnt            0.3500       59173.2      39        \n",
      "\n",
      "===============================================================================================\n",
      "COMPARATIVE ANALYSIS (CIFAR-10 + CNN): Answering Research Questions\n",
      "===============================================================================================\n",
      "\n",
      "1. QUATERNION vs REAL MLP (with CNN features):\n",
      "   ---------------------------------------------------------------------------\n",
      "   Real MLP accuracy:        0.4713 ± 0.0070\n",
      "   Quaternion accuracy:      0.4521 ± 0.0038\n",
      "   Gap:                      +1.92 percentage points\n",
      "   Performance retention:    95.9%\n",
      "\n",
      "   → Classical SU(2) (quaternions) captures 95.9% of\n",
      "     standard MLP performance with structured algebraic constraints on\n",
      "     rich CNN features (512-D from ImageNet-pretrained ResNet18).\n",
      "\n",
      "2. QUANTUM (no entanglement) vs REAL MLP (with CNN features):\n",
      "   ---------------------------------------------------------------------------\n",
      "   Real MLP accuracy:         0.4713 ± 0.0070\n",
      "   Quantum (no ent) accuracy: 0.4171 ± 0.0094\n",
      "   Gap:                       +5.42 percentage points\n",
      "   Performance retention:     88.5%\n",
      "\n",
      "   → Quantum circuits WITHOUT entanglement capture 88.5%\n",
      "     of MLP performance on rich CNN features, suggesting limited benefit\n",
      "     over classical rotation gates for CIFAR-10.\n",
      "\n",
      "3. QUANTUM (with entanglement) vs REAL MLP (with CNN features):\n",
      "   ---------------------------------------------------------------------------\n",
      "   Real MLP accuracy:         0.4713 ± 0.0070\n",
      "   Quantum (with ent) accuracy:0.3246 ± 0.0318\n",
      "   Gap:                       +14.68 percentage points\n",
      "   Performance retention:     68.9%\n",
      "\n",
      "   → Quantum circuits WITH entanglement capture 68.9%\n",
      "     of MLP performance on CNN features.\n",
      "\n",
      "4. ENTANGLEMENT EFFECT (with CNN features):\n",
      "   ---------------------------------------------------------------------------\n",
      "   Quantum (no ent) accuracy: 0.4171 ± 0.0094\n",
      "   Quantum (with ent) accuracy:0.3246 ± 0.0318\n",
      "   Improvement:               -9.26 percentage points\n",
      "\n",
      "   → Entanglement DOES NOT improve performance on CNN-powered CIFAR-10\n",
      "     → Rich features may saturate quantum advantage\n",
      "\n",
      "5. QUATERNION vs QUANTUM (no entanglement) - Core Research Question:\n",
      "   ---------------------------------------------------------------------------\n",
      "   Quaternion accuracy:       0.4521 ± 0.0038\n",
      "   Quantum (no ent) accuracy: 0.4171 ± 0.0094\n",
      "   Gap:                       +3.50 percentage points\n",
      "\n",
      "   → Quaternion networks OUTPERFORM quantum circuits without entanglement\n",
      "     by 3.50 percentage points on CNN features.\n",
      "\n",
      "   → Classical SU(2) (quaternions) SUFFICES for learning tasks addressable\n",
      "     by product-state quantum circuits, even with high-quality CNN features.\n",
      "     → Consistent with paper's findings on FashionMNIST (~6pp advantage).\n",
      "\n",
      "6. QUATERNION vs QUANTUM (with entanglement) on CNN features:\n",
      "   ---------------------------------------------------------------------------\n",
      "   Quaternion accuracy:       0.4521 ± 0.0038\n",
      "   Quantum (with ent) accuracy:0.3246 ± 0.0318\n",
      "   Gap:                       +12.76 percentage points\n",
      "\n",
      "   → Quaternions match or exceed entangled quantum performance,\n",
      "     suggesting entanglement provides limited benefit on CNN features.\n",
      "     → Measurement/optimization challenges may dominate on complex features.\n",
      "\n",
      "===============================================================================================\n",
      "KEY TAKEAWAYS FOR PAPER (CIFAR-10 + CNN)\n",
      "===============================================================================================\n",
      "\n",
      "✓ EMPIRICAL FINDINGS:\n",
      "  1. Quaternion networks achieve 95.9% of Real MLP performance\n",
      "     with structured SU(2) algebraic constraints on rich CNN features (512-D)\n",
      "     → Absolute accuracy: ~45.2% on CIFAR-10\n",
      "     → Tests quaternion geometry on high-quality ImageNet-pretrained features\n",
      "\n",
      "  2. Quaternions vs Quantum (no ent): +3.50 percentage point gap\n",
      "     → Classical SU(2) OUTPERFORMS quantum product-state circuits\n",
      "       (consistent with paper: quaternions >> quantum on FashionMNIST)\n",
      "     → Pattern generalizes from simple bottleneck (16-D) to CNN features (512-D)\n",
      "\n",
      "  3. Entanglement provides minimal/no benefit (-9.26pp)\n",
      "     → Rich CNN features may saturate quantum advantage\n",
      "     → Different pattern from FashionMNIST (0.6pp gain)\n",
      "\n",
      "✓ IMPLICATIONS:\n",
      "  • CNN-based comparison tests whether paper's findings hold with STRONG features\n",
      "  • Moving from learned bottleneck (16-D) → pretrained CNN (512-D) tests robustness\n",
      "  • If quaternions still match/beat quantum (like FashionMNIST):\n",
      "    → Strengthens claim that classical SU(2) suffices for product-state VQCs\n",
      "    → Shows pattern is NOT artifact of weak feature extraction\n",
      "  • If entanglement benefit persists (~0.5-1pp):\n",
      "    → Confirms entanglement as quantum boundary across feature qualities\n",
      "  • Higher absolute accuracies (vs. bottleneck version) validate CNN upgrade\n",
      "\n",
      "✓ COMPUTATIONAL EFFICIENCY:\n",
      "  • Real MLP:   14.2s (baseline)\n",
      "  • Quaternion: 36.1s (2.55x Real)\n",
      "  • Quantum (no ent): 64739.2s (4566.1x Real)\n",
      "    → Even with lightning.gpu, quantum is 1794.1x slower than quaternions\n",
      "    → Speedup gap narrows with CNN (GPU-accelerated forward pass)\n",
      "\n",
      "✓ CONTROLLED EXPERIMENTAL DESIGN:\n",
      "  • All models use IDENTICAL frozen ResNet18 CNN (~11M params)\n",
      "  • CNN pretrained on ImageNet → high-quality 512-D features\n",
      "  • Performance differences reflect HEAD ARCHITECTURE ONLY\n",
      "  • Validates paper's methodology with industrial-strength feature extraction\n",
      "\n",
      "✓ COMPARISON TO LEARNED BOTTLENECK:\n",
      "  • Learned bottleneck (3072→16): Tests quaternion geometry with minimal features\n",
      "  • CNN features (ResNet18→512): Tests quaternion geometry with rich features\n",
      "  • Together: Shows whether findings depend on feature quality or are robust\n",
      "===============================================================================================\n",
      "\n",
      "===============================================================================================\n",
      "ANALYSIS COMPLETE (CIFAR-10 + CNN)\n",
      "===============================================================================================\n",
      "\n",
      "All results saved in:\n",
      "  • realnet_cnn_cifar10_results.pt\n",
      "  • quatnet_cnn_cifar10_results.pt\n",
      "  • quantum_noent_cnn_cifar10_results.pt\n",
      "  • quantum_ent_cnn_cifar10_results.pt\n",
      "\n",
      "===============================================================================================\n",
      "COMPARISON TO PAPER (FashionMNIST with learned bottleneck)\n",
      "===============================================================================================\n",
      "\n",
      "Paper's key findings on FashionMNIST (learned 16-D bottleneck):\n",
      "  • Quaternions ≈ Real MLP (within 0.2pp)\n",
      "  • Quaternions >> Quantum-NoEnt (by ~2.4pp)\n",
      "  • Entanglement helps modestly (0.6pp gain)\n",
      "\n",
      "CIFAR-10 + CNN tests whether these patterns hold with:\n",
      "  • Harder task (color images, more complex)\n",
      "  • STRONG features (512-D ImageNet-pretrained CNN vs 16-D learned)\n",
      "  • Same architectural comparison (controlled design)\n",
      "  • Industrial-strength preprocessing (ResNet18)\n",
      "\n",
      "Key question: Do quaternions still match/beat quantum without rich features?\n",
      "  → If YES: Classical SU(2) sufficiency is robust finding\n",
      "  → If NO:  Feature quality matters for quaternion vs quantum comparison\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Block 5: Aggregate Results and Comparative Analysis with CNN (CIFAR-10)\n",
    "========================================================================\n",
    "Loads results from Blocks 1-4 and performs comprehensive comparison.\n",
    "\n",
    "Requirements:\n",
    "- realnet_cnn_cifar10_results.pt (from Block 1)\n",
    "- quatnet_cnn_cifar10_results.pt (from Block 2)\n",
    "- quantum_noent_cnn_cifar10_results.pt (from Block 3)\n",
    "- quantum_ent_cnn_cifar10_results.pt (from Block 4)\n",
    "\n",
    "Outputs:\n",
    "- Comprehensive comparison tables\n",
    "- Statistical analysis\n",
    "- Research question answers\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_results():\n",
    "    \"\"\"Load all results files\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    try:\n",
    "        real_data = torch.load(\"realnet_cnn_cifar10_results.pt\", weights_only=False)\n",
    "        results[\"Real\"] = real_data[\"results\"]\n",
    "        print(\"✓ Loaded RealNet-CNN (CIFAR-10) results\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"✗ realnet_cnn_cifar10_results.pt not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        quat_data = torch.load(\"quatnet_cnn_cifar10_results.pt\", weights_only=False)\n",
    "        results[\"Quat\"] = quat_data[\"results\"]\n",
    "        print(\"✓ Loaded QuatNet-CNN (CIFAR-10) results\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"✗ quatnet_cnn_cifar10_results.pt not found\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        qno_data = torch.load(\"quantum_noent_cnn_cifar10_results.pt\", weights_only=False)\n",
    "        results[\"QNoEnt\"] = qno_data[\"results\"]\n",
    "        print(\"✓ Loaded Quantum-NoEnt-CNN (CIFAR-10) results\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"⚠ quantum_noent_cnn_cifar10_results.pt not found (skipping)\")\n",
    "        results[\"QNoEnt\"] = []\n",
    "    \n",
    "    try:\n",
    "        qent_data = torch.load(\"quantum_ent_cnn_cifar10_results.pt\", weights_only=False)\n",
    "        results[\"QEnt\"] = qent_data[\"results\"]\n",
    "        print(\"✓ Loaded Quantum-Ent-CNN (CIFAR-10) results\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"⚠ quantum_ent_cnn_cifar10_results.pt not found (skipping)\")\n",
    "        results[\"QEnt\"] = []\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_summary_table(results):\n",
    "    \"\"\"Print aggregated summary table\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 95)\n",
    "    print(\"AGGREGATED RESULTS (CIFAR-10 + CNN) (mean ± std over 3 seeds)\")\n",
    "    print(\"=\" * 95)\n",
    "    print(f\"{'Model':<15} {'Accuracy':<20} {'Time (s)':<20} {'Epochs':<15} {'Trainable Params':<20}\")\n",
    "    print(\"-\" * 95)\n",
    "    \n",
    "    for name in [\"Real\", \"Quat\", \"QNoEnt\", \"QEnt\"]:\n",
    "        if not results[name]:\n",
    "            continue\n",
    "            \n",
    "        accs = [r[\"best_acc\"] for r in results[name]]\n",
    "        times = [r[\"time\"] for r in results[name]]\n",
    "        epochs = [r[\"epochs\"] for r in results[name]]\n",
    "        \n",
    "        acc_str = f\"{np.mean(accs):.4f} ± {np.std(accs):.4f}\"\n",
    "        time_str = f\"{np.mean(times):.1f} ± {np.std(times):.1f}\"\n",
    "        epoch_str = f\"{np.mean(epochs):.1f} ± {np.std(epochs):.1f}\"\n",
    "        \n",
    "        trainable = results[name][0][\"trainable_params\"]\n",
    "        param_str = f\"{trainable:,}\"\n",
    "        \n",
    "        print(f\"{name:<15} {acc_str:<20} {time_str:<20} {epoch_str:<15} {param_str:<20}\")\n",
    "    \n",
    "    print(\"-\" * 95)\n",
    "    print(f\"{'Frozen CNN':<15} {'(shared)':<20} {'-':<20} {'-':<15} {'~11M (ResNet18)':<20}\")\n",
    "    print(\"=\" * 95)\n",
    "\n",
    "\n",
    "def print_per_seed_table(results):\n",
    "    \"\"\"Print detailed per-seed results\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PER-SEED RESULTS (CIFAR-10 + CNN)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    seeds = [42, 123, 456]\n",
    "    \n",
    "    for seed_idx, seed in enumerate(seeds):\n",
    "        print(f\"\\nSeed {seed}:\")\n",
    "        print(f\"{'Model':<15} {'Accuracy':<12} {'Time (s)':<12} {'Epochs':<10}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for name in [\"Real\", \"Quat\", \"QNoEnt\", \"QEnt\"]:\n",
    "            if not results[name]:\n",
    "                continue\n",
    "            \n",
    "            r = results[name][seed_idx]\n",
    "            print(f\"{name:<15} {r['best_acc']:<12.4f} {r['time']:<12.1f} {r['epochs']:<10}\")\n",
    "\n",
    "\n",
    "def comparative_analysis(results):\n",
    "    \"\"\"Perform comparative analysis answering research questions\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 95)\n",
    "    print(\"COMPARATIVE ANALYSIS (CIFAR-10 + CNN): Answering Research Questions\")\n",
    "    print(\"=\" * 95)\n",
    "    \n",
    "    real_accs = [r[\"best_acc\"] for r in results[\"Real\"]]\n",
    "    quat_accs = [r[\"best_acc\"] for r in results[\"Quat\"]]\n",
    "    \n",
    "    def pct_gap(a, b):\n",
    "        \"\"\"Percentage point gap (a - b)\"\"\"\n",
    "        return (np.mean(a) - np.mean(b)) * 100.0\n",
    "    \n",
    "    def retention(a, b):\n",
    "        \"\"\"Percentage of performance retained\"\"\"\n",
    "        return (np.mean(a) / np.mean(b)) * 100.0\n",
    "    \n",
    "    print(\"\\n1. QUATERNION vs REAL MLP (with CNN features):\")\n",
    "    print(\"   \" + \"-\" * 75)\n",
    "    print(f\"   Real MLP accuracy:        {np.mean(real_accs):.4f} ± {np.std(real_accs):.4f}\")\n",
    "    print(f\"   Quaternion accuracy:      {np.mean(quat_accs):.4f} ± {np.std(quat_accs):.4f}\")\n",
    "    print(f\"   Gap:                      {pct_gap(real_accs, quat_accs):+.2f} percentage points\")\n",
    "    print(f\"   Performance retention:    {retention(quat_accs, real_accs):.1f}%\")\n",
    "    print(f\"\\n   → Classical SU(2) (quaternions) captures {retention(quat_accs, real_accs):.1f}% of\")\n",
    "    print(f\"     standard MLP performance with structured algebraic constraints on\")\n",
    "    print(f\"     rich CNN features (512-D from ImageNet-pretrained ResNet18).\")\n",
    "    \n",
    "    if results[\"QNoEnt\"]:\n",
    "        qno_accs = [r[\"best_acc\"] for r in results[\"QNoEnt\"]]\n",
    "        \n",
    "        print(\"\\n2. QUANTUM (no entanglement) vs REAL MLP (with CNN features):\")\n",
    "        print(\"   \" + \"-\" * 75)\n",
    "        print(f\"   Real MLP accuracy:         {np.mean(real_accs):.4f} ± {np.std(real_accs):.4f}\")\n",
    "        print(f\"   Quantum (no ent) accuracy: {np.mean(qno_accs):.4f} ± {np.std(qno_accs):.4f}\")\n",
    "        print(f\"   Gap:                       {pct_gap(real_accs, qno_accs):+.2f} percentage points\")\n",
    "        print(f\"   Performance retention:     {retention(qno_accs, real_accs):.1f}%\")\n",
    "        print(f\"\\n   → Quantum circuits WITHOUT entanglement capture {retention(qno_accs, real_accs):.1f}%\")\n",
    "        print(f\"     of MLP performance on rich CNN features, suggesting limited benefit\")\n",
    "        print(f\"     over classical rotation gates for CIFAR-10.\")\n",
    "    \n",
    "    if results[\"QEnt\"]:\n",
    "        qent_accs = [r[\"best_acc\"] for r in results[\"QEnt\"]]\n",
    "        \n",
    "        print(\"\\n3. QUANTUM (with entanglement) vs REAL MLP (with CNN features):\")\n",
    "        print(\"   \" + \"-\" * 75)\n",
    "        print(f\"   Real MLP accuracy:         {np.mean(real_accs):.4f} ± {np.std(real_accs):.4f}\")\n",
    "        print(f\"   Quantum (with ent) accuracy:{np.mean(qent_accs):.4f} ± {np.std(qent_accs):.4f}\")\n",
    "        print(f\"   Gap:                       {pct_gap(real_accs, qent_accs):+.2f} percentage points\")\n",
    "        print(f\"   Performance retention:     {retention(qent_accs, real_accs):.1f}%\")\n",
    "        print(f\"\\n   → Quantum circuits WITH entanglement capture {retention(qent_accs, real_accs):.1f}%\")\n",
    "        print(f\"     of MLP performance on CNN features.\")\n",
    "    \n",
    "    if results[\"QNoEnt\"] and results[\"QEnt\"]:\n",
    "        print(\"\\n4. ENTANGLEMENT EFFECT (with CNN features):\")\n",
    "        print(\"   \" + \"-\" * 75)\n",
    "        print(f\"   Quantum (no ent) accuracy: {np.mean(qno_accs):.4f} ± {np.std(qno_accs):.4f}\")\n",
    "        print(f\"   Quantum (with ent) accuracy:{np.mean(qent_accs):.4f} ± {np.std(qent_accs):.4f}\")\n",
    "        print(f\"   Improvement:               {pct_gap(qent_accs, qno_accs):+.2f} percentage points\")\n",
    "        \n",
    "        if np.mean(qent_accs) > np.mean(qno_accs):\n",
    "            improvement_pct = ((np.mean(qent_accs) - np.mean(qno_accs)) / np.mean(qno_accs)) * 100\n",
    "            print(f\"\\n   → Entanglement IMPROVES performance by {improvement_pct:.1f}%\")\n",
    "            print(f\"     (relative improvement over non-entangled baseline)\")\n",
    "            print(f\"     → Pattern consistent with paper findings (~0.6pp gain on FashionMNIST)\")\n",
    "        else:\n",
    "            print(f\"\\n   → Entanglement DOES NOT improve performance on CNN-powered CIFAR-10\")\n",
    "            print(f\"     → Rich features may saturate quantum advantage\")\n",
    "    \n",
    "    if results[\"QNoEnt\"]:\n",
    "        print(\"\\n5. QUATERNION vs QUANTUM (no entanglement) - Core Research Question:\")\n",
    "        print(\"   \" + \"-\" * 75)\n",
    "        print(f\"   Quaternion accuracy:       {np.mean(quat_accs):.4f} ± {np.std(quat_accs):.4f}\")\n",
    "        print(f\"   Quantum (no ent) accuracy: {np.mean(qno_accs):.4f} ± {np.std(qno_accs):.4f}\")\n",
    "        print(f\"   Gap:                       {pct_gap(quat_accs, qno_accs):+.2f} percentage points\")\n",
    "        \n",
    "        gap_abs = abs(pct_gap(quat_accs, qno_accs))\n",
    "        if gap_abs < 2.0:\n",
    "            print(f\"\\n   → Quaternion networks (classical SU(2)) CLOSELY APPROXIMATE quantum circuits\")\n",
    "            print(f\"     without entanglement (quantum SU(2)). Gap < 2 percentage points.\")\n",
    "            print(f\"\\n   → This supports the hypothesis that classical quaternion algebra can serve\")\n",
    "            print(f\"     as an effective implementation of SU(2) geometry on rich CNN features.\")\n",
    "        elif np.mean(quat_accs) > np.mean(qno_accs):\n",
    "            print(f\"\\n   → Quaternion networks OUTPERFORM quantum circuits without entanglement\")\n",
    "            print(f\"     by {gap_abs:.2f} percentage points on CNN features.\")\n",
    "            print(f\"\\n   → Classical SU(2) (quaternions) SUFFICES for learning tasks addressable\")\n",
    "            print(f\"     by product-state quantum circuits, even with high-quality CNN features.\")\n",
    "            print(f\"     → Consistent with paper's findings on FashionMNIST (~6pp advantage).\")\n",
    "        else:\n",
    "            print(f\"\\n   → Quantum circuits without entanglement OUTPERFORM quaternions\")\n",
    "            print(f\"     by {gap_abs:.2f} percentage points on CNN features.\")\n",
    "            print(f\"     → Different pattern from paper's FashionMNIST results\")\n",
    "    \n",
    "    if results[\"QEnt\"]:\n",
    "        print(\"\\n6. QUATERNION vs QUANTUM (with entanglement) on CNN features:\")\n",
    "        print(\"   \" + \"-\" * 75)\n",
    "        print(f\"   Quaternion accuracy:       {np.mean(quat_accs):.4f} ± {np.std(quat_accs):.4f}\")\n",
    "        print(f\"   Quantum (with ent) accuracy:{np.mean(qent_accs):.4f} ± {np.std(qent_accs):.4f}\")\n",
    "        print(f\"   Gap:                       {pct_gap(quat_accs, qent_accs):+.2f} percentage points\")\n",
    "        \n",
    "        if np.mean(qent_accs) > np.mean(quat_accs):\n",
    "            print(f\"\\n   → Entangled quantum circuits outperform quaternions, demonstrating\")\n",
    "            print(f\"     the value of quantum correlations beyond classical SU(2) rotations\")\n",
    "            print(f\"     when operating on rich CNN features.\")\n",
    "        else:\n",
    "            print(f\"\\n   → Quaternions match or exceed entangled quantum performance,\")\n",
    "            print(f\"     suggesting entanglement provides limited benefit on CNN features.\")\n",
    "            print(f\"     → Measurement/optimization challenges may dominate on complex features.\")\n",
    "\n",
    "\n",
    "def key_takeaways(results):\n",
    "    \"\"\"Summarize key takeaways for paper\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 95)\n",
    "    print(\"KEY TAKEAWAYS FOR PAPER (CIFAR-10 + CNN)\")\n",
    "    print(\"=\" * 95)\n",
    "    \n",
    "    real_accs = [r[\"best_acc\"] for r in results[\"Real\"]]\n",
    "    quat_accs = [r[\"best_acc\"] for r in results[\"Quat\"]]\n",
    "    \n",
    "    def retention(a, b):\n",
    "        return (np.mean(a) / np.mean(b)) * 100.0\n",
    "    \n",
    "    print(\"\\n✓ EMPIRICAL FINDINGS:\")\n",
    "    print(f\"  1. Quaternion networks achieve {retention(quat_accs, real_accs):.1f}% of Real MLP performance\")\n",
    "    print(f\"     with structured SU(2) algebraic constraints on rich CNN features (512-D)\")\n",
    "    print(f\"     → Absolute accuracy: ~{np.mean(quat_accs)*100:.1f}% on CIFAR-10\")\n",
    "    print(f\"     → Tests quaternion geometry on high-quality ImageNet-pretrained features\")\n",
    "    \n",
    "    if results[\"QNoEnt\"]:\n",
    "        qno_accs = [r[\"best_acc\"] for r in results[\"QNoEnt\"]]\n",
    "        gap = (np.mean(quat_accs) - np.mean(qno_accs)) * 100.0\n",
    "        gap_abs = abs(gap)\n",
    "        print(f\"\\n  2. Quaternions vs Quantum (no ent): {gap:+.2f} percentage point gap\")\n",
    "        if gap_abs < 2.0:\n",
    "            print(f\"     → Classical SU(2) effectively approximates quantum SU(2) without entanglement\")\n",
    "            print(f\"     → Pattern holds even with rich CNN features (not just learned bottlenecks)\")\n",
    "        elif gap > 0:\n",
    "            print(f\"     → Classical SU(2) OUTPERFORMS quantum product-state circuits\")\n",
    "            print(f\"       (consistent with paper: quaternions >> quantum on FashionMNIST)\")\n",
    "            print(f\"     → Pattern generalizes from simple bottleneck (16-D) to CNN features (512-D)\")\n",
    "        else:\n",
    "            print(f\"     → Quantum product-state circuits outperform classical SU(2)\")\n",
    "            print(f\"       (different pattern from FashionMNIST - may reflect CNN feature quality)\")\n",
    "    \n",
    "    if results[\"QEnt\"] and results[\"QNoEnt\"]:\n",
    "        qent_accs = [r[\"best_acc\"] for r in results[\"QEnt\"]]\n",
    "        qno_accs = [r[\"best_acc\"] for r in results[\"QNoEnt\"]]\n",
    "        ent_improvement_pp = (np.mean(qent_accs) - np.mean(qno_accs)) * 100.0\n",
    "        ent_improvement_pct = (ent_improvement_pp / (np.mean(qno_accs) * 100.0)) * 100.0\n",
    "        \n",
    "        if ent_improvement_pp > 0.3:\n",
    "            print(f\"\\n  3. Entanglement improves quantum performance by {ent_improvement_pp:.2f}pp\")\n",
    "            print(f\"     ({ent_improvement_pct:.1f}% relative improvement)\")\n",
    "            print(f\"     → Demonstrates measurable value of quantum correlations on CNN features\")\n",
    "            if abs(ent_improvement_pp - 0.6) < 0.3:\n",
    "                print(f\"     → Magnitude consistent with paper (~0.6pp gain on FashionMNIST)\")\n",
    "        else:\n",
    "            print(f\"\\n  3. Entanglement provides minimal/no benefit ({ent_improvement_pp:+.2f}pp)\")\n",
    "            print(f\"     → Rich CNN features may saturate quantum advantage\")\n",
    "            print(f\"     → Different pattern from FashionMNIST (0.6pp gain)\")\n",
    "    \n",
    "    print(\"\\n✓ IMPLICATIONS:\")\n",
    "    print(\"  • CNN-based comparison tests whether paper's findings hold with STRONG features\")\n",
    "    print(\"  • Moving from learned bottleneck (16-D) → pretrained CNN (512-D) tests robustness\")\n",
    "    print(\"  • If quaternions still match/beat quantum (like FashionMNIST):\")\n",
    "    print(\"    → Strengthens claim that classical SU(2) suffices for product-state VQCs\")\n",
    "    print(\"    → Shows pattern is NOT artifact of weak feature extraction\")\n",
    "    print(\"  • If entanglement benefit persists (~0.5-1pp):\")\n",
    "    print(\"    → Confirms entanglement as quantum boundary across feature qualities\")\n",
    "    print(\"  • Higher absolute accuracies (vs. bottleneck version) validate CNN upgrade\")\n",
    "    \n",
    "    print(\"\\n✓ COMPUTATIONAL EFFICIENCY:\")\n",
    "    real_time = np.mean([r[\"time\"] for r in results[\"Real\"]])\n",
    "    quat_time = np.mean([r[\"time\"] for r in results[\"Quat\"]])\n",
    "    print(f\"  • Real MLP:   {real_time:.1f}s (baseline)\")\n",
    "    print(f\"  • Quaternion: {quat_time:.1f}s ({quat_time/real_time:.2f}x Real)\")\n",
    "    \n",
    "    if results[\"QNoEnt\"]:\n",
    "        qno_time = np.mean([r[\"time\"] for r in results[\"QNoEnt\"]])\n",
    "        print(f\"  • Quantum (no ent): {qno_time:.1f}s ({qno_time/real_time:.1f}x Real)\")\n",
    "        print(f\"    → Even with lightning.gpu, quantum is {qno_time/quat_time:.1f}x slower than quaternions\")\n",
    "        print(f\"    → Speedup gap narrows with CNN (GPU-accelerated forward pass)\")\n",
    "    \n",
    "    print(\"\\n✓ CONTROLLED EXPERIMENTAL DESIGN:\")\n",
    "    print(\"  • All models use IDENTICAL frozen ResNet18 CNN (~11M params)\")\n",
    "    print(\"  • CNN pretrained on ImageNet → high-quality 512-D features\")\n",
    "    print(\"  • Performance differences reflect HEAD ARCHITECTURE ONLY\")\n",
    "    print(\"  • Validates paper's methodology with industrial-strength feature extraction\")\n",
    "    \n",
    "    print(\"\\n✓ COMPARISON TO LEARNED BOTTLENECK:\")\n",
    "    print(\"  • Learned bottleneck (3072→16): Tests quaternion geometry with minimal features\")\n",
    "    print(\"  • CNN features (ResNet18→512): Tests quaternion geometry with rich features\")\n",
    "    print(\"  • Together: Shows whether findings depend on feature quality or are robust\")\n",
    "    \n",
    "    print(\"=\" * 95)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 95)\n",
    "    print(\"BLOCK 5: AGGREGATE RESULTS AND COMPARATIVE ANALYSIS (CIFAR-10 + CNN)\")\n",
    "    print(\"=\" * 95)\n",
    "    \n",
    "    results = load_results()\n",
    "    \n",
    "    if results is None:\n",
    "        print(\"\\n✗ ERROR: Required results files not found.\")\n",
    "        print(\"Run Blocks 1 and 2 at minimum (Real and Quat) with CNN on CIFAR-10.\")\n",
    "        return\n",
    "    \n",
    "    # Summary table\n",
    "    print_summary_table(results)\n",
    "    \n",
    "    # Per-seed details\n",
    "    print_per_seed_table(results)\n",
    "    \n",
    "    # Comparative analysis\n",
    "    comparative_analysis(results)\n",
    "    \n",
    "    # Key takeaways\n",
    "    key_takeaways(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 95)\n",
    "    print(\"ANALYSIS COMPLETE (CIFAR-10 + CNN)\")\n",
    "    print(\"=\" * 95)\n",
    "    print(\"\\nAll results saved in:\")\n",
    "    print(\"  • realnet_cnn_cifar10_results.pt\")\n",
    "    print(\"  • quatnet_cnn_cifar10_results.pt\")\n",
    "    if results[\"QNoEnt\"]:\n",
    "        print(\"  • quantum_noent_cnn_cifar10_results.pt\")\n",
    "    if results[\"QEnt\"]:\n",
    "        print(\"  • quantum_ent_cnn_cifar10_results.pt\")\n",
    "    print(\"\\n\" + \"=\" * 95)\n",
    "    print(\"COMPARISON TO PAPER (FashionMNIST with learned bottleneck)\")\n",
    "    print(\"=\" * 95)\n",
    "    print(\"\\nPaper's key findings on FashionMNIST (learned 16-D bottleneck):\")\n",
    "    print(\"  • Quaternions ≈ Real MLP (within 0.2pp)\")\n",
    "    print(\"  • Quaternions >> Quantum-NoEnt (by ~2.4pp)\")\n",
    "    print(\"  • Entanglement helps modestly (0.6pp gain)\")\n",
    "    print(\"\\nCIFAR-10 + CNN tests whether these patterns hold with:\")\n",
    "    print(\"  • Harder task (color images, more complex)\")\n",
    "    print(\"  • STRONG features (512-D ImageNet-pretrained CNN vs 16-D learned)\")\n",
    "    print(\"  • Same architectural comparison (controlled design)\")\n",
    "    print(\"  • Industrial-strength preprocessing (ResNet18)\")\n",
    "    print(\"\\nKey question: Do quaternions still match/beat quantum without rich features?\")\n",
    "    print(\"  → If YES: Classical SU(2) sufficiency is robust finding\")\n",
    "    print(\"  → If NO:  Feature quality matters for quaternion vs quantum comparison\")\n",
    "    print(\"=\" * 95)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1065e4-7464-4132-a7a9-ae3a59f0408f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
